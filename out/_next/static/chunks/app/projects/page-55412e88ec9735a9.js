(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[895],{7242:function(e,n,t){Promise.resolve().then(t.bind(t,9475))},1881:function(e,n,t){"use strict";t.d(n,{Card:function(){return l}});var r=t(9109),i=t(8295),o=t(6229),a=t(8092),s=t(6783);function c(){let e=(0,r._)(["radial-gradient(240px at ","px ","px, white, transparent)"]);return c=function(){return e},e}let l=e=>{let{children:n}=e,t=(0,o.q)(0,{stiffness:500,damping:100}),r=(0,o.q)(0,{stiffness:500,damping:100}),l=(0,a.Y)(c(),t,r),d={maskImage:l,WebkitMaskImage:l};return(0,i.jsxs)("div",{onMouseMove:function(e){let{currentTarget:n,clientX:i,clientY:o}=e,{left:a,top:s}=n.getBoundingClientRect();t.set(i-a),r.set(o-s)},className:"overflow-hidden relative duration-700 border rounded-xl hover:bg-zinc-800/10 group md:gap-8 hover:border-zinc-400/50 border-zinc-600 ",children:[(0,i.jsxs)("div",{className:"pointer-events-none",children:[(0,i.jsx)("div",{className:"absolute inset-0 z-0  transition duration-1000 [mask-image:linear-gradient(black,transparent)]"}),(0,i.jsx)(s.E.div,{className:"absolute inset-0 z-10  bg-gradient-to-br opacity-100  via-zinc-100/10  transition duration-1000 group-hover:opacity-50 ",style:d}),(0,i.jsx)(s.E.div,{className:"absolute inset-0 z-10 opacity-0 mix-blend-overlay transition duration-1000 group-hover:opacity-100",style:d})]}),n]})}},3292:function(e,n,t){"use strict";t.d(n,{W:function(){return s}});var r=t(8295),i=t(3001),o=t(2456),a=t(3387);let s=()=>{let e=(0,a.useRef)(null),[n,t]=(0,a.useState)(!0);return(0,a.useEffect)(()=>{if(!e.current)return;let n=new IntersectionObserver(e=>{let[n]=e;return t(n.isIntersecting)});return n.observe(e.current),()=>n.disconnect()},[]),(0,r.jsx)("header",{ref:e,children:(0,r.jsx)("div",{className:"fixed inset-x-0 top-0 z-50 backdrop-blur  duration-200 border-b  ".concat(n?"bg-zinc-900/0 border-transparent":"bg-zinc-900/500  border-zinc-800 "),children:(0,r.jsxs)("div",{className:"container flex flex-row-reverse items-center justify-between p-6 mx-auto",children:[(0,r.jsxs)("div",{className:"flex justify-between gap-8",children:[(0,r.jsx)(o.default,{href:"/projects",className:"duration-200 text-zinc-400 hover:text-zinc-100",children:"Projects"}),(0,r.jsx)(o.default,{href:"/photography",className:"duration-200 text-zinc-400 hover:text-zinc-100",children:"Photography"}),(0,r.jsx)(o.default,{href:"/contact",className:"duration-200 text-zinc-400 hover:text-zinc-100",children:"Contact"})]}),(0,r.jsx)(o.default,{href:"/",className:"duration-200 text-zinc-300 hover:text-zinc-100",children:(0,r.jsx)(i.Z,{className:"w-6 h-6 "})})]})})})}},9475:function(e,n,t){"use strict";t.r(n),t.d(n,{default:function(){return d}});var r=t(8295),i=t(2456),o=t(3387),a=JSON.parse('[{"published":true,"title":"Apple News Redesign","description":"A UI/UX redesign of Apple News, focused on improving targeted topic exploration.","date":"2024-11-01T00:00:00.000Z","videoDemo":"https://drive.google.com/file/d/1Wvnj5VlVZ2ZDlpA3jY0shWCFeX1pY7S-/view?usp=sharing","figmaPrototype":"https://www.figma.com/proto/Kw4vlrqiyajBpHX0cuBXtV/Designs?page-id=362%3A11891&node-id=372-5855&viewport=-1052%2C-1219%2C0.39&t=QZaxJlsTQRZtLWN2-1&scaling=scale-down&content-scaling=fixed&starting-point-node-id=372%3A5855 - Figma","displayDate":"Fall 2024","category":"Mobile","body":{"raw":"\\n<div className=\\"flex flex-col md:flex-row gap-12 items-start mb-8\\">\\n  <div className=\\"flex-1\\">\\n    This redesign tackles Apple News\'s tendency to prioritize daily headlines and personalized snippets, making it hard to form a concise, multidimensional view of a single topic including broader context. This redesign groups content into discrete topics, offers tailored exploration via article recommendations sorted by topic and source type, integrates an in-app chat for follow-up questions and personalized guidance, and lets users follow unlimited topics while viewing a \\"coverage profile\\" that highlights their biases and suggests ways to diversify their perspective. \\n    This project was initiated in Stanford\'s CS 247A (Design for AI) class and follows the RITE method (Rapid Iterative Testing and Evaluation) and makes use of [Microsoft\'s [HAX toolkit](https://www.microsoft.com/en-us/haxtoolkit/ai-guidelines/) and [playbook](https://microsoft.github.io/HAXPlaybook/) for Human-AI Interaction.\\n  </div>\\n  <div className=\\"md:w-2/5\\">\\n  <iframe\\n  width=\\"100%\\"\\n  height=\\"400\\"\\n  src=\\"https://youtube.com/embed/EoSCksIJRKY\\"\\n  title=\\"CS 247A Apple News Figma Redesign\\"\\n  frameborder=\\"0\\"\\n  allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\"\\n  allowfullscreen\\n  style={{  marginBottom: \'2rem\' }}\\n/>\\n  </div>\\n</div>\\n\\n## Project Progression\\n\\nWe created a Product Requirements Doc (PRD), outlining the following: \\n- target audience\\n- user needs\\n- scenarios including sunny day scenarios, stress cases, possible failure states\\n- relevant AI guideleines\\n- required data and features\\n- comparators\\n- stakeholders\\n\\nView the whole PRD [here](https://docs.google.com/document/d/1jR4HpJoxbiMDpi2W6Q0I3YQJVLuL7wZS/edit?usp=sharing&ouid=103933716377033248565&rtpof=true&sd=true) for the full outline. \\n\\n### Ideation\\nWe used the Crazy 8s brainstorming method to quickly sketch out ideas (8 sketches in 5 minutes).\\n<div\\n  style={{\\n    display: \'flex\',\\n  \\n  }}\\n>\\n<img src=\\"/apple-news/crazy8-1.png\\" alt=\\"lo-fi sketch\\" style={{ margin: \'2rem 0\' }} width=\\"50%\\" />\\n<img src=\\"/apple-news/crazy8-2.png\\" alt=\\"lo-fi sketch\\" style={{ margin: \'2rem 0\' }} width=\\"50%\\" />\\n</div>\\n\\n\\n### RITE Testing Plan\\nTo iterate on our designs, we used the RITE testing method with incorporation of A/B testing. We ran four different stages of testing involving a total of 8 participants. During each testing phase, users were asked to use the \\"think aloud\\" approach, verbally narrating their observations and critiques.\\n\\nWe first created lo-fi sketches that focused more directly on our final concept. Testing questions in this stage mostly focused on \\nevaluating user interest in the overall concept and understanding of the layout of our redesigned topic and chat pages.\\n<div\\n  style={{\\n    display: \'flex\',\\n  \\n  }}\\n>\\n<img src=\\"/apple-news/lo-fi-1.jpg\\" alt=\\"lo-fi sketch\\" style={{ margin: \'2rem 0\' }} width=\\"60%\\" />\\n<img src=\\"/apple-news/lo-fi-2.png\\" alt=\\"lo-fi sketch\\" style={{ margin: \'2rem 0\' }} width=\\"60%\\" />\\n</div>\\n\\nThe second iteration involved designing grayscale interfaces with a focus on testing ease of navigation from one screen to the next. We avoid color at this stage to ensure design critiques were more focused on organization questions, rather than aesthetics.\\n<img src=\\"/apple-news/applenews-grayscale.png\\" alt=\\"lo-fi sketch\\" width=\\"100%\\" />\\n\\nThe third iteration involved a significant pivot from our previous chat-focused designs, incorporating additional pages for displaying topics, showing a reader\'s coverage of an issue, diverse sources beyond traditional news outlets, and more. \\n\\n<img src=\\"/apple-news/applenews-colored.png\\" alt=\\"lo-fi sketch\\" width=\\"100%\\" />\\n\\nWe made heavy use of Figma\'s components and variants feature to rapidly iterate and create multiple options for A/B testing. \\n<img src=\\"/apple-news/applenews-components.png\\" alt=\\"lo-fi sketch\\" width=\\"100%\\" />\\n\\n\\nThe final stage focused on scoping out a functional, interactive protoype. Testing was still done at this stage to gauge improvements for the future. \\nCheck out the final Figma prototype [here](https://www.figma.com/proto/Kw4vlrqiyajBpHX0cuBXtV/Designs?page-id=362%3A11891&node-id=372-5855&viewport=-1052%2C-1219%2C0.39&t=QZaxJlsTQRZtLWN2-1&scaling=scale-down&content-scaling=fixed&starting-point-node-id=372%3A5855).\\n\\n","code":"var Component=(()=>{var p=Object.create;var o=Object.defineProperty;var h=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var m=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),w=(t,e)=>{for(var n in e)o(t,n,{get:e[n],enumerable:!0})},r=(t,e,n,a)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let s of g(e))!f.call(t,s)&&s!==n&&o(t,s,{get:()=>e[s],enumerable:!(a=h(e,s))||a.enumerable});return t};var y=(t,e,n)=>(n=t!=null?p(u(t)):{},r(e||!t||!t.__esModule?o(n,\\"default\\",{value:t,enumerable:!0}):n,t)),v=t=>r(o({},\\"__esModule\\",{value:!0}),t);var c=m((T,l)=>{l.exports=_jsx_runtime});var A={};w(A,{default:()=>x,frontmatter:()=>k});var i=y(c()),k={title:\\"Apple News Redesign\\",description:\\"A UI/UX redesign of Apple News, focused on improving targeted topic exploration.\\",date:\\"2024-11-01\\",displayDate:\\"Fall 2024\\",published:!0,category:\\"Mobile\\",videoDemo:\\"https://drive.google.com/file/d/1Wvnj5VlVZ2ZDlpA3jY0shWCFeX1pY7S-/view?usp=sharing\\",figmaPrototype:\\"https://www.figma.com/proto/Kw4vlrqiyajBpHX0cuBXtV/Designs?page-id=362%3A11891&node-id=372-5855&viewport=-1052%2C-1219%2C0.39&t=QZaxJlsTQRZtLWN2-1&scaling=scale-down&content-scaling=fixed&starting-point-node-id=372%3A5855 - Figma\\"};function d(t){let e=Object.assign({p:\\"p\\",a:\\"a\\",h2:\\"h2\\",span:\\"span\\",ul:\\"ul\\",li:\\"li\\",h3:\\"h3\\"},t.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(\\"div\\",{className:\\"flex flex-col md:flex-row gap-12 items-start mb-8\\",children:[(0,i.jsx)(\\"div\\",{className:\\"flex-1\\",children:(0,i.jsxs)(e.p,{children:[`This redesign tackles Apple News\'s tendency to prioritize daily headlines and personalized snippets, making it hard to form a concise, multidimensional view of a single topic including broader context. This redesign groups content into discrete topics, offers tailored exploration via article recommendations sorted by topic and source type, integrates an in-app chat for follow-up questions and personalized guidance, and lets users follow unlimited topics while viewing a \\"coverage profile\\" that highlights their biases and suggests ways to diversify their perspective.\\nThis project was initiated in Stanford\'s CS 247A (Design for AI) class and follows the RITE method (Rapid Iterative Testing and Evaluation) and makes use of [Microsoft\'s `,(0,i.jsx)(e.a,{href:\\"https://www.microsoft.com/en-us/haxtoolkit/ai-guidelines/\\",children:\\"HAX toolkit\\"}),\\" and \\",(0,i.jsx)(e.a,{href:\\"https://microsoft.github.io/HAXPlaybook/\\",children:\\"playbook\\"}),\\" for Human-AI Interaction.\\"]})}),(0,i.jsx)(\\"div\\",{className:\\"md:w-2/5\\",children:(0,i.jsx)(\\"iframe\\",{width:\\"100%\\",height:\\"400\\",src:\\"https://youtube.com/embed/EoSCksIJRKY\\",title:\\"CS 247A Apple News Figma Redesign\\",frameborder:\\"0\\",allow:\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\",allowfullscreen:!0,style:{marginBottom:\\"2rem\\"}})})]}),`\\n`,(0,i.jsxs)(e.h2,{id:\\"project-progression\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#project-progression\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Project Progression\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"We created a Product Requirements Doc (PRD), outlining the following:\\"}),`\\n`,(0,i.jsxs)(e.ul,{children:[`\\n`,(0,i.jsx)(e.li,{children:\\"target audience\\"}),`\\n`,(0,i.jsx)(e.li,{children:\\"user needs\\"}),`\\n`,(0,i.jsx)(e.li,{children:\\"scenarios including sunny day scenarios, stress cases, possible failure states\\"}),`\\n`,(0,i.jsx)(e.li,{children:\\"relevant AI guideleines\\"}),`\\n`,(0,i.jsx)(e.li,{children:\\"required data and features\\"}),`\\n`,(0,i.jsx)(e.li,{children:\\"comparators\\"}),`\\n`,(0,i.jsx)(e.li,{children:\\"stakeholders\\"}),`\\n`]}),`\\n`,(0,i.jsxs)(e.p,{children:[\\"View the whole PRD \\",(0,i.jsx)(e.a,{href:\\"https://docs.google.com/document/d/1jR4HpJoxbiMDpi2W6Q0I3YQJVLuL7wZS/edit?usp=sharing&ouid=103933716377033248565&rtpof=true&sd=true\\",children:\\"here\\"}),\\" for the full outline.\\"]}),`\\n`,(0,i.jsxs)(e.h3,{id:\\"ideation\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#ideation\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Ideation\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"We used the Crazy 8s brainstorming method to quickly sketch out ideas (8 sketches in 5 minutes).\\"}),`\\n`,(0,i.jsxs)(\\"div\\",{style:{display:\\"flex\\"},children:[(0,i.jsx)(\\"img\\",{src:\\"/apple-news/crazy8-1.png\\",alt:\\"lo-fi sketch\\",style:{margin:\\"2rem 0\\"},width:\\"50%\\"}),(0,i.jsx)(\\"img\\",{src:\\"/apple-news/crazy8-2.png\\",alt:\\"lo-fi sketch\\",style:{margin:\\"2rem 0\\"},width:\\"50%\\"})]}),`\\n`,(0,i.jsxs)(e.h3,{id:\\"rite-testing-plan\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#rite-testing-plan\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"RITE Testing Plan\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\'To iterate on our designs, we used the RITE testing method with incorporation of A/B testing. We ran four different stages of testing involving a total of 8 participants. During each testing phase, users were asked to use the \\"think aloud\\" approach, verbally narrating their observations and critiques.\'}),`\\n`,(0,i.jsx)(e.p,{children:`We first created lo-fi sketches that focused more directly on our final concept. Testing questions in this stage mostly focused on\\nevaluating user interest in the overall concept and understanding of the layout of our redesigned topic and chat pages.`}),`\\n`,(0,i.jsxs)(\\"div\\",{style:{display:\\"flex\\"},children:[(0,i.jsx)(\\"img\\",{src:\\"/apple-news/lo-fi-1.jpg\\",alt:\\"lo-fi sketch\\",style:{margin:\\"2rem 0\\"},width:\\"60%\\"}),(0,i.jsx)(\\"img\\",{src:\\"/apple-news/lo-fi-2.png\\",alt:\\"lo-fi sketch\\",style:{margin:\\"2rem 0\\"},width:\\"60%\\"})]}),`\\n`,(0,i.jsx)(e.p,{children:\\"The second iteration involved designing grayscale interfaces with a focus on testing ease of navigation from one screen to the next. We avoid color at this stage to ensure design critiques were more focused on organization questions, rather than aesthetics.\\"}),`\\n`,(0,i.jsx)(\\"img\\",{src:\\"/apple-news/applenews-grayscale.png\\",alt:\\"lo-fi sketch\\",width:\\"100%\\"}),`\\n`,(0,i.jsx)(e.p,{children:\\"The third iteration involved a significant pivot from our previous chat-focused designs, incorporating additional pages for displaying topics, showing a reader\'s coverage of an issue, diverse sources beyond traditional news outlets, and more.\\"}),`\\n`,(0,i.jsx)(\\"img\\",{src:\\"/apple-news/applenews-colored.png\\",alt:\\"lo-fi sketch\\",width:\\"100%\\"}),`\\n`,(0,i.jsx)(e.p,{children:\\"We made heavy use of Figma\'s components and variants feature to rapidly iterate and create multiple options for A/B testing.\\"}),`\\n`,(0,i.jsx)(\\"img\\",{src:\\"/apple-news/applenews-components.png\\",alt:\\"lo-fi sketch\\",width:\\"100%\\"}),`\\n`,(0,i.jsxs)(e.p,{children:[`The final stage focused on scoping out a functional, interactive protoype. Testing was still done at this stage to gauge improvements for the future.\\nCheck out the final Figma prototype `,(0,i.jsx)(e.a,{href:\\"https://www.figma.com/proto/Kw4vlrqiyajBpHX0cuBXtV/Designs?page-id=362%3A11891&node-id=372-5855&viewport=-1052%2C-1219%2C0.39&t=QZaxJlsTQRZtLWN2-1&scaling=scale-down&content-scaling=fixed&starting-point-node-id=372%3A5855\\",children:\\"here\\"}),\\".\\"]})]})}function b(t={}){let{wrapper:e}=t.components||{};return e?(0,i.jsx)(e,Object.assign({},t,{children:(0,i.jsx)(d,t)})):d(t)}var x=b;return v(A);})();\\n;return Component;"},"_id":"projects/apple-news.mdx","_raw":{"sourceFilePath":"projects/apple-news.mdx","sourceFileName":"apple-news.mdx","sourceFileDir":"projects","contentType":"mdx","flattenedPath":"projects/apple-news"},"type":"Project","path":"projects/apple-news","slug":"apple-news"},{"published":true,"title":"US Book Ban Visualization","description":"Series of data visualizations created from PEN America\'s book ban dataset from 2021-2022.","date":"2023-02-01T00:00:00.000Z","url":"https://book-bans-2022.netlify.app","tools":["d3"],"displayDate":"Winter 2023","category":"Web","body":{"raw":"\\n# Summary\\n\\nIn Winter 2023, I worked on a group project (Stanford CS 448B) to analyze and visualize PEN America\'s dataset that covers all instances of book bans from July 1, 2021 through June 30, 2022. These bans have typically disproportionately affected people of underrepresented communities such as the LGBTQ+ community and people of color, but there have not been many extensive visualizations that shed light on the significant impact of book bans in more detail.\\n\\nAll visualizations seen below can be interacted with live at this [site](https://book-bans-2022.netlify.app). \\n# Timeline of Book Bans by State (July 2021 - June 2022)\\n The visualization below is an interactive timeline of the past several months that show the top 10 states with the highest number of bans. You can click the \\"Play\\" button to animate the changes from month to month, or you can click on any of the months on the slider manually. You can also switch between the bar graph from showing the number of bans occurring in each individual month (i.e. non-cumulative) or the cumulative number of bans from July 2021. \\n<img src=\\"/bans/bans-1.png\\" alt=\\"screenshot of interactive timeline showing book bans in top 10 states between 2021 to 2022\\" style={{ margin: \'2rem 0\' }} />\\n\\n# Where do book bans in the US occur the most?\\nThe visualization below is an interactive chloropleth map of the U.S. with gray mapping to zero bans and dark red mapping to the highest number of bans. You can hover over a state to see its total number of bans initiated and its number of unique districts that initiated a ban. If you click on a state, you can see a bar chart mapping the name of each banning district to the number of bans initiated by that district.\\n<img src=\\"/bans/bans-2.png\\" alt=\\"screenshot showing chloropleth map of US based on number of banned books\\" style={{ margin: \'2rem 0\' }} />\\n\\n# What kinds of books are being targeted?\\n## Titles of the Most Banned Books\\nBelow are the titles of the most banned books, ordered from most frequently banned to least. Clicking on a title will show the districts and states in which it is banned. You can also search for any title or author you are interested in seeing whether it has been banned or not.\\n<img src=\\"/bans/bans-3.png\\" alt=\\"screenshot of visualization showing rankings of banned books\\" style={{ margin: \'2rem 0\' }} />\\n## What words are shared most across titles?\\nBelow is a word cloud of the most commonly occurring words in the titles of the banned books. The size of the word correlates to its frequency, and clicking on a word will reveal all of the books with that word in its title. Hovering over a listed book title will show the districts in which that book is banned. \\n<img src=\\"/bans/bans-4.png\\" alt=\\"screenshot of word cloud showing banned book titles\\" style={{margin: \'2rem 0\' }} />\\n","code":"var Component=(()=>{var d=Object.create;var i=Object.defineProperty;var b=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,f=Object.prototype.hasOwnProperty;var p=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),g=(t,e)=>{for(var a in e)i(t,a,{get:e[a],enumerable:!0})},r=(t,e,a,s)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let o of m(e))!f.call(t,o)&&o!==a&&i(t,o,{get:()=>e[o],enumerable:!(s=b(e,o))||s.enumerable});return t};var k=(t,e,a)=>(a=t!=null?d(u(t)):{},r(e||!t||!t.__esModule?i(a,\\"default\\",{value:t,enumerable:!0}):a,t)),w=t=>r(i({},\\"__esModule\\",{value:!0}),t);var l=p((x,h)=>{h.exports=_jsx_runtime});var j={};g(j,{default:()=>N,frontmatter:()=>y});var n=k(l()),y={title:\\"US Book Ban Visualization\\",description:\\"Series of data visualizations created from PEN America\'s book ban dataset from 2021-2022.\\",date:\\"2023-02-01\\",displayDate:\\"Winter 2023\\",url:\\"https://book-bans-2022.netlify.app\\",published:!0,category:\\"Web\\",tools:[\\"d3\\"]};function c(t){let e=Object.assign({h1:\\"h1\\",a:\\"a\\",span:\\"span\\",p:\\"p\\",h2:\\"h2\\"},t.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.h1,{id:\\"summary\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#summary\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),`\\n`,(0,n.jsx)(e.p,{children:\\"In Winter 2023, I worked on a group project (Stanford CS 448B) to analyze and visualize PEN America\'s dataset that covers all instances of book bans from July 1, 2021 through June 30, 2022. These bans have typically disproportionately affected people of underrepresented communities such as the LGBTQ+ community and people of color, but there have not been many extensive visualizations that shed light on the significant impact of book bans in more detail.\\"}),`\\n`,(0,n.jsxs)(e.p,{children:[\\"All visualizations seen below can be interacted with live at this \\",(0,n.jsx)(e.a,{href:\\"https://book-bans-2022.netlify.app\\",children:\\"site\\"}),\\".\\"]}),`\\n`,(0,n.jsxs)(e.h1,{id:\\"timeline-of-book-bans-by-state-july-2021---june-2022\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#timeline-of-book-bans-by-state-july-2021---june-2022\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Timeline of Book Bans by State (July 2021 - June 2022)\\"]}),`\\n`,(0,n.jsx)(e.p,{children:\'The visualization below is an interactive timeline of the past several months that show the top 10 states with the highest number of bans. You can click the \\"Play\\" button to animate the changes from month to month, or you can click on any of the months on the slider manually. You can also switch between the bar graph from showing the number of bans occurring in each individual month (i.e. non-cumulative) or the cumulative number of bans from July 2021.\'}),`\\n`,(0,n.jsx)(\\"img\\",{src:\\"/bans/bans-1.png\\",alt:\\"screenshot of interactive timeline showing book bans in top 10 states between 2021 to 2022\\",style:{margin:\\"2rem 0\\"}}),`\\n`,(0,n.jsxs)(e.h1,{id:\\"where-do-book-bans-in-the-us-occur-the-most\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#where-do-book-bans-in-the-us-occur-the-most\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Where do book bans in the US occur the most?\\"]}),`\\n`,(0,n.jsx)(e.p,{children:\\"The visualization below is an interactive chloropleth map of the U.S. with gray mapping to zero bans and dark red mapping to the highest number of bans. You can hover over a state to see its total number of bans initiated and its number of unique districts that initiated a ban. If you click on a state, you can see a bar chart mapping the name of each banning district to the number of bans initiated by that district.\\"}),`\\n`,(0,n.jsx)(\\"img\\",{src:\\"/bans/bans-2.png\\",alt:\\"screenshot showing chloropleth map of US based on number of banned books\\",style:{margin:\\"2rem 0\\"}}),`\\n`,(0,n.jsxs)(e.h1,{id:\\"what-kinds-of-books-are-being-targeted\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#what-kinds-of-books-are-being-targeted\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"What kinds of books are being targeted?\\"]}),`\\n`,(0,n.jsxs)(e.h2,{id:\\"titles-of-the-most-banned-books\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#titles-of-the-most-banned-books\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Titles of the Most Banned Books\\"]}),`\\n`,(0,n.jsx)(e.p,{children:\\"Below are the titles of the most banned books, ordered from most frequently banned to least. Clicking on a title will show the districts and states in which it is banned. You can also search for any title or author you are interested in seeing whether it has been banned or not.\\"}),`\\n`,(0,n.jsx)(\\"img\\",{src:\\"/bans/bans-3.png\\",alt:\\"screenshot of visualization showing rankings of banned books\\",style:{margin:\\"2rem 0\\"}}),`\\n`,(0,n.jsxs)(e.h2,{id:\\"what-words-are-shared-most-across-titles\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#what-words-are-shared-most-across-titles\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"What words are shared most across titles?\\"]}),`\\n`,(0,n.jsx)(e.p,{children:\\"Below is a word cloud of the most commonly occurring words in the titles of the banned books. The size of the word correlates to its frequency, and clicking on a word will reveal all of the books with that word in its title. Hovering over a listed book title will show the districts in which that book is banned.\\"}),`\\n`,(0,n.jsx)(\\"img\\",{src:\\"/bans/bans-4.png\\",alt:\\"screenshot of word cloud showing banned book titles\\",style:{margin:\\"2rem 0\\"}})]})}function v(t={}){let{wrapper:e}=t.components||{};return e?(0,n.jsx)(e,Object.assign({},t,{children:(0,n.jsx)(c,t)})):c(t)}var N=v;return w(j);})();\\n;return Component;"},"_id":"projects/book-bans.mdx","_raw":{"sourceFilePath":"projects/book-bans.mdx","sourceFileName":"book-bans.mdx","sourceFileDir":"projects","contentType":"mdx","flattenedPath":"projects/book-bans"},"type":"Project","path":"projects/book-bans","slug":"book-bans"},{"published":true,"title":"EcoVision","description":"A VR experience that fosters sustainable behavior change through visualization and positive reinforcement of sustainable daily habits.","date":"2024-03-01T00:00:00.000Z","designPitch":"https://tome.app/karina-chen/ecovision-clx0q9ocd05zcoe5yjftec8sc","videoDemo":"https://www.youtube.com/watch?v=69AfsrRTzGE","tools":["Figma","Bezi"],"displayDate":"Spring 2024","category":"XR","body":{"raw":"\\n<iframe\\n  width=\\"100%\\"\\n  height=\\"400\\"\\n  src=\\"https://www.youtube.com/embed/69AfsrRTzGE\\"\\n  title=\\"EcoVision Video Demo\\"\\n  frameborder=\\"0\\"\\n  allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\"\\n  allowfullscreen\\n  style={{ marginBottom: \'2rem\' }}\\n/>\\n\\n# Summary\\n\\nEcovision is a VR experience that fosters sustainable behavior change on an individual level through visualization and positive reinforcement of sustainable daily habits such as eating and showering. This initiative targets students by making the outcomes of their actions more immediate and tangible through to-scale waste visualizations and live transformation of saved quantities into floral growth. EcoVision was started as a Stanford class project for DESIGN 284: Designing for Extended Realities in Spring of 2024.\\n\\nA summary of our design process can be found below. For more info, check out our slide deck [here](https://tome.app/karina-chen/ecovision-clx0q9ocd05zcoe5yjftec8sc).\\n\\n# Needfinding\\n\\nWe interviewed 10+ sustainability educators, peer advocates, and students with limited sustainability awareness to uncover prevalent misconceptions and knowledge gaps. Our key findings:\\n\\n#### Visualization Gap\\nEducators find it challenging to convey abstract concepts like dimensional analysis; students struggle to grasp the scale and impact of their actions without concrete examples\\n\\n#### Disconnect in immediate impact\\nThe lack of immediate, personal feedback leaves students feeling disconnected from the real-world consequences of their actions\\n\\n#### Beyond Guilt\\nThe limitations of guilt as a motivator and the success of positive reinforcement strategies in engaging students to adopt more sustainable behaviors\\n\\n\\n\\n# Prototyping Journey\\n\\n## IRL Prototyping: Testing User Journey\\n\\nTo evaluate XR interactions, we had users act out real-life motions to test the narrative journey of the experience.\\n\\n#### Scenario\\nUsers washed their hands while a facilitator filled a bucket at the adjacent sink. The user observed the collected water and poured it onto a patch of grass, with a plant substituted to simulate the VR experience.\\n\\n#### Key design questions\\nHow do users like visualizing their water waste volumetrically? How do users feel about transforming the \\"waste\\" into a new item, like a plant?\\n\\n<img src=\\"/ecovision/ecovision-1.png\\" alt=\\"IRL Prototyping\\" style={{  margin: \'2rem 0\' }} />\\n\\n## Sims Prototyping: Testing Interactions\\n\\nTo explore the \\"daily living tasks\\" concept, we used The Sims, allowing for custom 3D environments and controlled agent actions.\\n\\n#### Setup\\nGame with a basic house, including a kitchen, bathroom, and living room. The backyard had plants and empty planter boxes. Food was left to spoil for compost visualization, and a pool of water represented water waste. Users were tasked to complete tasks in each section of the environment and plant in the garden.\\n\\n#### Key design questions\\nHow do users like the flow of living in a simulated environment and performing tasks? Are they satisfied with the level of control?\\n\\n<img src=\\"/ecovision/ecovision-2.png\\" alt=\\"Sims Prototyping\\" style={{ margin: \'2rem 0\' }} />\\n\\n# Final Product\\n\\nOur final prototype was developed in Bezi and features the following:\\n\\n#### Onboarding\\nIntroduces the user to the experience; simple, intuitive tutorial to guide users on how to navigate and interact, including a dashboard across the user experience that tracks user\'s saved food and water waste\\n\\n#### Dining Hall\\nGuides user to eat a meal and throw waste into a compost bin, comparing user\'s food waste habits to the average American to highlight personal impact.\\n\\n#### Dorm Bathroom\\nProvides real-time visualization of water usage during daily activities like showering, helping users understand their consumption patterns\\n\\n#### Garden\\nIllustrates how saved waste can be repurposed to sustain plants over time, emphasizing tangible, positive change\\n\\n<img src=\\"/ecovision/ecovision-3.png\\" alt=\\"Final Product\\" style={{ margin: \'2rem 0\' }} />\\n\\n","code":"var Component=(()=>{var h=Object.create;var s=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var p=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var f=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),b=(n,e)=>{for(var a in e)s(n,a,{get:e[a],enumerable:!0})},r=(n,e,a,o)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let t of p(e))!g.call(n,t)&&t!==a&&s(n,t,{get:()=>e[t],enumerable:!(o=u(e,t))||o.enumerable});return n};var k=(n,e,a)=>(a=n!=null?h(m(n)):{},r(e||!n||!n.__esModule?s(a,\\"default\\",{value:n,enumerable:!0}):a,n)),y=n=>r(s({},\\"__esModule\\",{value:!0}),n);var l=f((j,c)=>{c.exports=_jsx_runtime});var x={};b(x,{default:()=>N,frontmatter:()=>v});var i=k(l()),v={title:\\"EcoVision\\",description:\\"A VR experience that fosters sustainable behavior change through visualization and positive reinforcement of sustainable daily habits.\\",displayDate:\\"Spring 2024\\",date:\\"2024-03-01\\",published:!0,designPitch:\\"https://tome.app/karina-chen/ecovision-clx0q9ocd05zcoe5yjftec8sc\\",videoDemo:\\"https://www.youtube.com/watch?v=69AfsrRTzGE\\",category:\\"XR\\",tools:[\\"Figma\\",\\"Bezi\\"]};function d(n){let e=Object.assign({h1:\\"h1\\",a:\\"a\\",span:\\"span\\",p:\\"p\\",h4:\\"h4\\",h2:\\"h2\\"},n.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(\\"iframe\\",{width:\\"100%\\",height:\\"400\\",src:\\"https://www.youtube.com/embed/69AfsrRTzGE\\",title:\\"EcoVision Video Demo\\",frameborder:\\"0\\",allow:\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\",allowfullscreen:!0,style:{marginBottom:\\"2rem\\"}}),`\\n`,(0,i.jsxs)(e.h1,{id:\\"summary\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#summary\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"Ecovision is a VR experience that fosters sustainable behavior change on an individual level through visualization and positive reinforcement of sustainable daily habits such as eating and showering. This initiative targets students by making the outcomes of their actions more immediate and tangible through to-scale waste visualizations and live transformation of saved quantities into floral growth. EcoVision was started as a Stanford class project for DESIGN 284: Designing for Extended Realities in Spring of 2024.\\"}),`\\n`,(0,i.jsxs)(e.p,{children:[\\"A summary of our design process can be found below. For more info, check out our slide deck \\",(0,i.jsx)(e.a,{href:\\"https://tome.app/karina-chen/ecovision-clx0q9ocd05zcoe5yjftec8sc\\",children:\\"here\\"}),\\".\\"]}),`\\n`,(0,i.jsxs)(e.h1,{id:\\"needfinding\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#needfinding\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Needfinding\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"We interviewed 10+ sustainability educators, peer advocates, and students with limited sustainability awareness to uncover prevalent misconceptions and knowledge gaps. Our key findings:\\"}),`\\n`,(0,i.jsxs)(e.h4,{id:\\"visualization-gap\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#visualization-gap\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Visualization Gap\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"Educators find it challenging to convey abstract concepts like dimensional analysis; students struggle to grasp the scale and impact of their actions without concrete examples\\"}),`\\n`,(0,i.jsxs)(e.h4,{id:\\"disconnect-in-immediate-impact\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#disconnect-in-immediate-impact\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Disconnect in immediate impact\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"The lack of immediate, personal feedback leaves students feeling disconnected from the real-world consequences of their actions\\"}),`\\n`,(0,i.jsxs)(e.h4,{id:\\"beyond-guilt\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#beyond-guilt\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Beyond Guilt\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"The limitations of guilt as a motivator and the success of positive reinforcement strategies in engaging students to adopt more sustainable behaviors\\"}),`\\n`,(0,i.jsxs)(e.h1,{id:\\"prototyping-journey\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#prototyping-journey\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Prototyping Journey\\"]}),`\\n`,(0,i.jsxs)(e.h2,{id:\\"irl-prototyping-testing-user-journey\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#irl-prototyping-testing-user-journey\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"IRL Prototyping: Testing User Journey\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"To evaluate XR interactions, we had users act out real-life motions to test the narrative journey of the experience.\\"}),`\\n`,(0,i.jsxs)(e.h4,{id:\\"scenario\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#scenario\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Scenario\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"Users washed their hands while a facilitator filled a bucket at the adjacent sink. The user observed the collected water and poured it onto a patch of grass, with a plant substituted to simulate the VR experience.\\"}),`\\n`,(0,i.jsxs)(e.h4,{id:\\"key-design-questions\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#key-design-questions\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Key design questions\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\'How do users like visualizing their water waste volumetrically? How do users feel about transforming the \\"waste\\" into a new item, like a plant?\'}),`\\n`,(0,i.jsx)(\\"img\\",{src:\\"/ecovision/ecovision-1.png\\",alt:\\"IRL Prototyping\\",style:{margin:\\"2rem 0\\"}}),`\\n`,(0,i.jsxs)(e.h2,{id:\\"sims-prototyping-testing-interactions\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#sims-prototyping-testing-interactions\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Sims Prototyping: Testing Interactions\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\'To explore the \\"daily living tasks\\" concept, we used The Sims, allowing for custom 3D environments and controlled agent actions.\'}),`\\n`,(0,i.jsxs)(e.h4,{id:\\"setup\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#setup\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Setup\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"Game with a basic house, including a kitchen, bathroom, and living room. The backyard had plants and empty planter boxes. Food was left to spoil for compost visualization, and a pool of water represented water waste. Users were tasked to complete tasks in each section of the environment and plant in the garden.\\"}),`\\n`,(0,i.jsxs)(e.h4,{id:\\"key-design-questions-1\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#key-design-questions-1\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Key design questions\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"How do users like the flow of living in a simulated environment and performing tasks? Are they satisfied with the level of control?\\"}),`\\n`,(0,i.jsx)(\\"img\\",{src:\\"/ecovision/ecovision-2.png\\",alt:\\"Sims Prototyping\\",style:{margin:\\"2rem 0\\"}}),`\\n`,(0,i.jsxs)(e.h1,{id:\\"final-product\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#final-product\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Final Product\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"Our final prototype was developed in Bezi and features the following:\\"}),`\\n`,(0,i.jsxs)(e.h4,{id:\\"onboarding\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#onboarding\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Onboarding\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"Introduces the user to the experience; simple, intuitive tutorial to guide users on how to navigate and interact, including a dashboard across the user experience that tracks user\'s saved food and water waste\\"}),`\\n`,(0,i.jsxs)(e.h4,{id:\\"dining-hall\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#dining-hall\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Dining Hall\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"Guides user to eat a meal and throw waste into a compost bin, comparing user\'s food waste habits to the average American to highlight personal impact.\\"}),`\\n`,(0,i.jsxs)(e.h4,{id:\\"dorm-bathroom\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#dorm-bathroom\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Dorm Bathroom\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"Provides real-time visualization of water usage during daily activities like showering, helping users understand their consumption patterns\\"}),`\\n`,(0,i.jsxs)(e.h4,{id:\\"garden\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#garden\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Garden\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"Illustrates how saved waste can be repurposed to sustain plants over time, emphasizing tangible, positive change\\"}),`\\n`,(0,i.jsx)(\\"img\\",{src:\\"/ecovision/ecovision-3.png\\",alt:\\"Final Product\\",style:{margin:\\"2rem 0\\"}})]})}function w(n={}){let{wrapper:e}=n.components||{};return e?(0,i.jsx)(e,Object.assign({},n,{children:(0,i.jsx)(d,n)})):d(n)}var N=w;return y(x);})();\\n;return Component;"},"_id":"projects/ecovision.mdx","_raw":{"sourceFilePath":"projects/ecovision.mdx","sourceFileName":"ecovision.mdx","sourceFileDir":"projects","contentType":"mdx","flattenedPath":"projects/ecovision"},"type":"Project","path":"projects/ecovision","slug":"ecovision"},{"published":true,"title":"EduSketch","description":"A tool for automatic educational storyboard generation, aimed at teachers of 5th-8th grade students with Down Syndrome.","date":"2024-03-01T00:00:00.000Z","url":"https://edusketch-bebb4.web.app/","videoDemo":"https://www.youtube.com/watch?v=vjSrKwjf3ZU","figmaPrototype":"https://www.figma.com/proto/dkZz3xJMVMGM15HIyJq4bA/Figma-Prototypes?page-id=&node-id=176-357&node-type=canvas&viewport=-1256%2C-414%2C0.14&t=xsLPHUoOgsrTFgHl-1&scaling=contain&content-scaling=fixed&starting-point-node-id=176%3A357","github":"https://github.com/ckunchur/EduSketch","tools":["Figma","React","OpenAI"],"displayDate":"Spring 2024","category":"Web","body":{"raw":"\\n<iframe\\n  width=\\"100%\\"\\n  height=\\"400\\"\\n  src=\\"https://www.youtube.com/embed/vjSrKwjf3ZU\\"\\n  title=\\"EduSketch Final Demo Video\\"\\n  frameBorder=\\"0\\"\\n  allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\"\\n  allowFullScreen\\n  style={{ marginBottom: \'2rem\' }}\\n/>\\n\\n\\n# Summary\\nEduSketch is an AI tool for automatically generating educational storyboards, initially aimed at helping students with Down Syndrome in the 5th-8th grade age range, a transition point during which the school curriculum difficulty tends to rapidly increase. Visual learning tools are commonly used to help engage children with Down Syndrome, but existing tools often fail to capture complex ideas, and caregivers often find themselves creating material, a solution that is not sustainable nor accessible. EduSketch aims to offer a easy to use tool for teachers or caregivers to convert complex ideas and documentation into visually engaging and compact storyboards.\\n\\nEduSketch was started as a Stanford class group project for CS 377Q: Designing for Accessibility in Spring of 2024.\\n\\n# Features\\nEduSketch allows users to upload a PDF or copy/paste text as input for storyboard generation. Customization options include selecting an art style, adjusting the reading level, and the number of panels to include in the board. The board can be viewed in slideshow and grid formats, each panel captioned by a short description. The final storyboard can be exported in PDF format for widespread sharing.\\n\\n# Needfinding\\nWe reached out to the Stanford Down Syndrome Center for help with recruitment, receiving over 20 responses expressing interest. Due to time constraints, we selected 4 participants with Down Syndrome alongside guardians to virtually interview.\\nOur participants ranged in age from 17-24 years old (we were initually focused on college learning but later pivoted). Our needfinding questions were scoped to emphasize learning experiences and associated challenges.\\n\\n# Prototyping & User Testing\\n\\nDuring testing, we asked users to go through the storyboard creation task flow. We set the context, explaining what the tool does, and telling them in advance that the file being used for the test is from a 5th grade history book. They were guided to “upload” and view the file, customize the art style, and view their custom storyboard.\\nWe collected data on how long it took them to complete this task as well as how many and what type of errors they made along the way. Any questions or moments of confusion were noted.\\n\\n## Med-Fi Figma Prototype\\nWe iterated on an interactive Figma prototpe, implementing feedback from two rounds of user testing. We prototype interactions in Figma for uploading a PDF, selecting an art style, and viewing the generated storyboard in both slideshow and grid format, with hover interactions for viewing more details about each scene.\\n\\n<img src=\\"/edusketch/edusketch-frames-p1.png\\" alt=\\"lo-fi sketch\\"  width=\\"100%\\" />\\n<img src=\\"/edusketch/edusketch-frames-p2.png\\" alt=\\"lo-fi sketch\\"  width=\\"100%\\" />\\n<img src=\\"/edusketch/edusketch-frames-p3.png\\" alt=\\"lo-fi sketch\\"  width=\\"100%\\" />\\n\\n## Hi-fi Prototype\\n\\nAfter user testing the interactive Figma prototype, we implemented our idea as a React web application. To generate the text and image pairs for each storyboard panel, we used OpenAI\'s GPT-4o model for condensing and chunking the extracted PDF text (or pasted text) and DALL\xb7E 3 for image generation.\\nThe live app can be tested [here](https://edusketch-bebb4.web.app/).\\n","code":"var Component=(()=>{var h=Object.create;var o=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,m=Object.prototype.hasOwnProperty;var f=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),w=(n,e)=>{for(var a in e)o(n,a,{get:e[a],enumerable:!0})},s=(n,e,a,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let i of g(e))!m.call(n,i)&&i!==a&&o(n,i,{get:()=>e[i],enumerable:!(r=p(e,i))||r.enumerable});return n};var y=(n,e,a)=>(a=n!=null?h(u(n)):{},s(e||!n||!n.__esModule?o(a,\\"default\\",{value:n,enumerable:!0}):a,n)),b=n=>s(o({},\\"__esModule\\",{value:!0}),n);var d=f((F,c)=>{c.exports=_jsx_runtime});var S={};w(S,{default:()=>x,frontmatter:()=>k});var t=y(d()),k={title:\\"EduSketch\\",description:\\"A tool for automatic educational storyboard generation, aimed at teachers of 5th-8th grade students with Down Syndrome.\\",github:\\"https://github.com/ckunchur/EduSketch\\",url:\\"https://edusketch-bebb4.web.app/\\",videoDemo:\\"https://www.youtube.com/watch?v=vjSrKwjf3ZU\\",figmaPrototype:\\"https://www.figma.com/proto/dkZz3xJMVMGM15HIyJq4bA/Figma-Prototypes?page-id=&node-id=176-357&node-type=canvas&viewport=-1256%2C-414%2C0.14&t=xsLPHUoOgsrTFgHl-1&scaling=contain&content-scaling=fixed&starting-point-node-id=176%3A357\\",displayDate:\\"Spring 2024\\",date:\\"2024-03-01\\",published:!0,category:\\"Web\\",tools:[\\"Figma\\",\\"React\\",\\"OpenAI\\"]};function l(n){let e=Object.assign({h1:\\"h1\\",a:\\"a\\",span:\\"span\\",p:\\"p\\",h2:\\"h2\\"},n.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(\\"iframe\\",{width:\\"100%\\",height:\\"400\\",src:\\"https://www.youtube.com/embed/vjSrKwjf3ZU\\",title:\\"EduSketch Final Demo Video\\",frameBorder:\\"0\\",allow:\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\",allowFullScreen:!0,style:{marginBottom:\\"2rem\\"}}),`\\n`,(0,t.jsxs)(e.h1,{id:\\"summary\\",children:[(0,t.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#summary\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),`\\n`,(0,t.jsx)(e.p,{children:\\"EduSketch is an AI tool for automatically generating educational storyboards, initially aimed at helping students with Down Syndrome in the 5th-8th grade age range, a transition point during which the school curriculum difficulty tends to rapidly increase. Visual learning tools are commonly used to help engage children with Down Syndrome, but existing tools often fail to capture complex ideas, and caregivers often find themselves creating material, a solution that is not sustainable nor accessible. EduSketch aims to offer a easy to use tool for teachers or caregivers to convert complex ideas and documentation into visually engaging and compact storyboards.\\"}),`\\n`,(0,t.jsx)(e.p,{children:\\"EduSketch was started as a Stanford class group project for CS 377Q: Designing for Accessibility in Spring of 2024.\\"}),`\\n`,(0,t.jsxs)(e.h1,{id:\\"features\\",children:[(0,t.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#features\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Features\\"]}),`\\n`,(0,t.jsx)(e.p,{children:\\"EduSketch allows users to upload a PDF or copy/paste text as input for storyboard generation. Customization options include selecting an art style, adjusting the reading level, and the number of panels to include in the board. The board can be viewed in slideshow and grid formats, each panel captioned by a short description. The final storyboard can be exported in PDF format for widespread sharing.\\"}),`\\n`,(0,t.jsxs)(e.h1,{id:\\"needfinding\\",children:[(0,t.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#needfinding\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Needfinding\\"]}),`\\n`,(0,t.jsx)(e.p,{children:`We reached out to the Stanford Down Syndrome Center for help with recruitment, receiving over 20 responses expressing interest. Due to time constraints, we selected 4 participants with Down Syndrome alongside guardians to virtually interview.\\nOur participants ranged in age from 17-24 years old (we were initually focused on college learning but later pivoted). Our needfinding questions were scoped to emphasize learning experiences and associated challenges.`}),`\\n`,(0,t.jsxs)(e.h1,{id:\\"prototyping--user-testing\\",children:[(0,t.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#prototyping--user-testing\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Prototyping & User Testing\\"]}),`\\n`,(0,t.jsx)(e.p,{children:`During testing, we asked users to go through the storyboard creation task flow. We set the context, explaining what the tool does, and telling them in advance that the file being used for the test is from a 5th grade history book. They were guided to \\\\u201Cupload\\\\u201D and view the file, customize the art style, and view their custom storyboard.\\nWe collected data on how long it took them to complete this task as well as how many and what type of errors they made along the way. Any questions or moments of confusion were noted.`}),`\\n`,(0,t.jsxs)(e.h2,{id:\\"med-fi-figma-prototype\\",children:[(0,t.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#med-fi-figma-prototype\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Med-Fi Figma Prototype\\"]}),`\\n`,(0,t.jsx)(e.p,{children:\\"We iterated on an interactive Figma prototpe, implementing feedback from two rounds of user testing. We prototype interactions in Figma for uploading a PDF, selecting an art style, and viewing the generated storyboard in both slideshow and grid format, with hover interactions for viewing more details about each scene.\\"}),`\\n`,(0,t.jsx)(\\"img\\",{src:\\"/edusketch/edusketch-frames-p1.png\\",alt:\\"lo-fi sketch\\",width:\\"100%\\"}),`\\n`,(0,t.jsx)(\\"img\\",{src:\\"/edusketch/edusketch-frames-p2.png\\",alt:\\"lo-fi sketch\\",width:\\"100%\\"}),`\\n`,(0,t.jsx)(\\"img\\",{src:\\"/edusketch/edusketch-frames-p3.png\\",alt:\\"lo-fi sketch\\",width:\\"100%\\"}),`\\n`,(0,t.jsxs)(e.h2,{id:\\"hi-fi-prototype\\",children:[(0,t.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#hi-fi-prototype\\",children:(0,t.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Hi-fi Prototype\\"]}),`\\n`,(0,t.jsxs)(e.p,{children:[`After user testing the interactive Figma prototype, we implemented our idea as a React web application. To generate the text and image pairs for each storyboard panel, we used OpenAI\'s GPT-4o model for condensing and chunking the extracted PDF text (or pasted text) and DALL\\\\xB7E 3 for image generation.\\nThe live app can be tested `,(0,t.jsx)(e.a,{href:\\"https://edusketch-bebb4.web.app/\\",children:\\"here\\"}),\\".\\"]})]})}function v(n={}){let{wrapper:e}=n.components||{};return e?(0,t.jsx)(e,Object.assign({},n,{children:(0,t.jsx)(l,n)})):l(n)}var x=v;return b(S);})();\\n;return Component;"},"_id":"projects/edusketch.mdx","_raw":{"sourceFilePath":"projects/edusketch.mdx","sourceFileName":"edusketch.mdx","sourceFileDir":"projects","contentType":"mdx","flattenedPath":"projects/edusketch"},"type":"Project","path":"projects/edusketch","slug":"edusketch"},{"published":true,"title":"FindYourFood","description":"A cross-platform mobile app for recipe searching and grocery shopping.","date":"2022-10-01T00:00:00.000Z","repository":"ckunchur/FindYourFood","tools":["ReactNative"],"displayDate":"Fall 2022","category":"Mobile","body":{"raw":"\\nI designed a ReactNative app called FindYourFood (as part of Stanford CS 47 class) that makes recipe searching and grocery shopping simpler. Users can search for a recipe directly, or upload a picture of food to find a matching recipe, and add ingredients to their shopping list! The app also returns the closest grocery stores to a user. \\n<img src=\\"/findyourfood-1.png\\" alt=\\"screenshots of FindYourFood app\\" style={{ margin: \'2rem 0\' }} />\\n","code":"var Component=(()=>{var l=Object.create;var s=Object.defineProperty;var u=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var h=Object.getPrototypeOf,m=Object.prototype.hasOwnProperty;var f=(e,o)=>()=>(o||e((o={exports:{}}).exports,o),o.exports),F=(e,o)=>{for(var r in o)s(e,r,{get:o[r],enumerable:!0})},i=(e,o,r,a)=>{if(o&&typeof o==\\"object\\"||typeof o==\\"function\\")for(let n of g(o))!m.call(e,n)&&n!==r&&s(e,n,{get:()=>o[n],enumerable:!(a=u(o,n))||a.enumerable});return e};var y=(e,o,r)=>(r=e!=null?l(h(e)):{},i(o||!e||!e.__esModule?s(r,\\"default\\",{value:e,enumerable:!0}):r,e)),x=e=>i(s({},\\"__esModule\\",{value:!0}),e);var p=f((C,c)=>{c.exports=_jsx_runtime});var M={};F(M,{default:()=>b,frontmatter:()=>j});var t=y(p()),j={title:\\"FindYourFood\\",description:\\"A cross-platform mobile app for recipe searching and grocery shopping.\\",date:\\"2022-10-01\\",displayDate:\\"Fall 2022\\",published:!0,repository:\\"ckunchur/FindYourFood\\",category:\\"Mobile\\",tools:[\\"ReactNative\\"]};function d(e){let o=Object.assign({p:\\"p\\"},e.components);return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(o.p,{children:\\"I designed a ReactNative app called FindYourFood (as part of Stanford CS 47 class) that makes recipe searching and grocery shopping simpler. Users can search for a recipe directly, or upload a picture of food to find a matching recipe, and add ingredients to their shopping list! The app also returns the closest grocery stores to a user.\\"}),`\\n`,(0,t.jsx)(\\"img\\",{src:\\"/findyourfood-1.png\\",alt:\\"screenshots of FindYourFood app\\",style:{margin:\\"2rem 0\\"}})]})}function _(e={}){let{wrapper:o}=e.components||{};return o?(0,t.jsx)(o,Object.assign({},e,{children:(0,t.jsx)(d,e)})):d(e)}var b=_;return x(M);})();\\n;return Component;"},"_id":"projects/findyourfood.mdx","_raw":{"sourceFilePath":"projects/findyourfood.mdx","sourceFileName":"findyourfood.mdx","sourceFileDir":"projects","contentType":"mdx","flattenedPath":"projects/findyourfood"},"type":"Project","path":"projects/findyourfood","slug":"findyourfood"},{"published":true,"title":"MindCompass","description":"A mixed reality app designed to help kids practice immersive, guided meditation.","date":"2023-04-01T00:00:00.000Z","url":"https://hci.stanford.edu/courses/cs147/2023/au/projects/AccessingHealthcare/MindCompass/","videoDemo":"https://www.youtube.com/watch?v=Kt_2jgPzT4I","tools":["Figma","Unity"],"displayDate":"Fall 2023","category":"XR","body":{"raw":"  <iframe\\n  width=\\"100%\\"\\n  height=\\"400\\"\\n  src=\\"https://www.youtube.com/embed/Kt_2jgPzT4I\\"\\n  title=\\"MindCompass Final Demo\\"\\n  frameborder=\\"0\\"\\n  allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\"\\n  allowfullscreen\\n  style={{marginBottom: \'2rem\' }}\\n/>\\n\\n# Summary\\n\\nMindCompass is a mixed reality app designed to help kids practice immersive, guided meditation in the comfort of their own home, promoting independence and healthy emotional regulation. Users are guided by friendly creatures and transported to mystical lands, earning rewards for building good habits. This project was started as part of Stanford’s Introduction to Human Computer Interaction (CS 147) class in Fall of 2023, in which our group won the “Best Overall Project” and “Most Novel” awards for our efforts.\\n\\nCheck out our full design process at our project [website](https://hci.stanford.edu/courses/cs147/2023/au/projects/AccessingHealthcare/MindCompass/) including needfinding, experience prototyping, annotated task flows, low-fi user testing, heuristic evaluation, our hi-fi Unity demo, and more! The entire process from start to finish is also documented in our [final report](https://docs.google.com/document/d/1Mk08d4agAaUTJZbPJzXVYzkIkdLyrchrN66KLymyBYI/edit?usp=sharing).\\n\\n# Needfinding + Solution Brainstorming\\nOur problem scope initially focused on parenting and caretaking in general. We conducted two rounds of needfinding interviews, recruiting a total of 6 participants, all parents who spanned a range of occupations and child raising experience. \\nWhen interviewing participants, we focused on a few themed guiding questions. A few examples are listed below:\\n - Roadblocks: What roadblocks hamper(ed) you from performing your childcare duties to the fullest?\\n - Trust: How did you navigate different sources of advice and learn what to trust?\\n - Support: What kind of support network was available to you when raising a child?\\n\\n ## Result Synthesis\\nOur needfinding interviews were incredibly insightful in highlighting key areas and issues faced by parents and caretakers. For each interviewee, we generated individual empathy maps (what the interviewee says, thinks, does, and feels) and noted key quotes and insights from their interview. After repeating this process for each interviewee, we identified several overarching themes:\\n - Self-discovery: allowing for self-discovery is just as (if not more) important than outside advice during the parenting process.\\n - Support: a strong support group and network of peers can be critical for relieving stress during parenting. \\n - No generic solutions: you can’t bundle all “childcare” together, even if kids are seemingly similar in age; each kid is different from each other. \\n - Pressure: New parents will weigh every decision with a lot of anxiety in order to try to be perfect.\\n\\n## POVs & How Might Wes\\nAs a team, we developed POV (point of view) statements based on two of our strongest interviews and generated “How Might We” (HMW) statements to brainstorm possible pain points that could be addressed by expanded solutions.\\nWe brainstormed 10-15 solutions for each HMW statement. \\n\\nBelow is a small sample of our findings from initial needfinding interviews and our generation of potential “how might we” statements and solutions. \\n<img src=\\"/mindcompass/mindcompass-1.png\\" alt=\\"lo-fi sketch\\"  width=\\"100%\\" />\\n<img src=\\"/mindcompass/mindcompass-2.png\\" alt=\\"lo-fi sketch\\"  width=\\"100%\\" />\\n<img src=\\"/mindcompass/mindcompass-3.png\\" alt=\\"lo-fi sketch\\"  width=\\"100%\\" />\\n\\n## Experience prototypes\\nWe next created 3 different experience prototypes, one corresponding to each of our 3 top solutions. These prototypes were designed to test assumptions we are making about our users and their behavior (not any UI or design itself). We narrowed down on assumptions that if false, would cause our idea to fail and brainstormed lightweight tests to validate those critical assumptions. \\n\\n\\nBelow is a description of 1 of the 3 prototypes:\\n\\n- **Assumption**: parents need help gamifying individual parenting tasks\\n- **Set up**: 1) Conversation about their general parenting experience, 2) Sketchnoting exercise - interviewees were shown an AI-generated photo of a common gamified parenting task (“Here comes the airplane!”)  \\n- **Questions**: \\"What does this photo remind you of?\\", \\"Do you similarly gamify tasks with your child?\\", \\"What’s a hard childcare task for you? Try to gamify it.\\"\\n\\n<img src=\\"/mindcompass/experience-prototypes.png\\" alt=\\"lo-fi sketch\\"  width=\\"100%\\" />\\n\\nTakeaways from this prototype were:\\n  - Parents lack awareness of how to gamify certain tasks  \\n  - Children have more energy and imagination than their parents\\n  - Parents *are* searching for answers, but don’t know what works for their child  \\n  - Decreasing the cognitive stress of seeking better ways to gamify tasks empowers both the parent and child\\n\\n## Final Solution \\nFollowing our experience prototyping results and reflecting on our past interviews, we decided to narrow down on the question: How can we meet the needs of parents and kids by helping kids regulate their emotions in a way that is appealing to their childish imagination and sense of wonder?\\n\\nWhile the question may seem to differ quite a bit from our prior focus on addressing parenting needs alone, our gamification experience prototype and our previous needfinding chat with an elementary school teacher, heavily influenced our new direction. She emphasized the importance of teaching kids emotional control, especially after the COVID-19 pandemic, going out of her way to show us various materials and resources she relies on to support the students she teaches. Our focus on supporting a fundamental need of children also directly removes the emotional burden and stress placed on parents to teach such skills. By supporting young children, we also support new parents. \\n\\nThus, our final solution resulted in the following: \\n**Using gamification in mixed reality to guide children through the practice of meditation, simultaneously promoting independence and healthy emotional regulation.**\\n\\n## Initial Lo-fi Prototype\\n\\nWe created a paper lo-fi prototype of our XR screens walking through selection and experience of a meditation activity. We tested this prototype on multiple participants in person, having them point to various parts of the \\"screens\\" and narrate their thinking aloud. \\n\\n\\n<img src=\\"/mindcompass/mindcompass-4.png\\" alt=\\"lo-fi sketch\\"  width=\\"100%\\" />\\n<img src=\\"/mindcompass/mindcompass-5.jpeg\\" alt=\\"lo-fi sketch\\"  width=\\"100%\\" />\\n\\n\\n# Figma Medium-Fi Prototype\\nBelow are a sample of the XR screens I designed in Figma including onboarding, meditation customization settings, experience completion, and rewards. \\nCheck out our interactive Figma demo [here](https://www.figma.com/proto/KpWBUwZBQ54ysAo6pPKiqA/MindCompass-Med-fi-Prototype?type=design&node-id=102-9885&t=Jgl4SeAPzJmJYQNc-1&scaling=min-zoom&page-id=0%3A1&starting-point-node-id=102%3A9885&show-proto-sidebar=1). Note that some aspects of the designs below were updated after Figma prototyping and were incorporated later in the actual hi-fi demo (below).\\n<img src=\\"/mindcompass/mindcompass-6.png\\" alt=\\"lo-fi sketch\\"  width=\\"100%\\" />\\n\\n\\n# Unity Hi-Fi Demo Video\\n\\nOur final application was developed in Unity for the Meta Quest 3. We used a Figma to Unity plugin to directly import the 2D walkthrough and rewards screens. We used Eleven Labs to generate the audio for the meditation narrative. Upon completing the onboarding, users are transported to a calming grassy landscape where a friendly panda named \\"Pando\\" guides them through the experience. \\nCheck out the video demo [here](https://www.youtube.com/watch?v=Kt_2jgPzT4I)!","code":"var Component=(()=>{var h=Object.create;var a=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var f=(n,e)=>()=>(e||n((e={exports:{}}).exports,e),e.exports),w=(n,e)=>{for(var t in e)a(n,t,{get:e[t],enumerable:!0})},s=(n,e,t,r)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let o of m(e))!g.call(n,o)&&o!==t&&a(n,o,{get:()=>e[o],enumerable:!(r=p(e,o))||r.enumerable});return n};var y=(n,e,t)=>(t=n!=null?h(u(n)):{},s(e||!n||!n.__esModule?a(t,\\"default\\",{value:n,enumerable:!0}):t,n)),b=n=>s(a({},\\"__esModule\\",{value:!0}),n);var l=f((M,d)=>{d.exports=_jsx_runtime});var N={};w(N,{default:()=>x,frontmatter:()=>k});var i=y(l()),k={title:\\"MindCompass\\",description:\\"A mixed reality app designed to help kids practice immersive, guided meditation.\\",date:\\"2023-04-01\\",displayDate:\\"Fall 2023\\",url:\\"https://hci.stanford.edu/courses/cs147/2023/au/projects/AccessingHealthcare/MindCompass/\\",published:!0,category:\\"XR\\",videoDemo:\\"https://www.youtube.com/watch?v=Kt_2jgPzT4I\\",tools:[\\"Figma\\",\\"Unity\\"]};function c(n){let e=Object.assign({h1:\\"h1\\",a:\\"a\\",span:\\"span\\",p:\\"p\\",ul:\\"ul\\",li:\\"li\\",h2:\\"h2\\",strong:\\"strong\\",em:\\"em\\"},n.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(\\"iframe\\",{width:\\"100%\\",height:\\"400\\",src:\\"https://www.youtube.com/embed/Kt_2jgPzT4I\\",title:\\"MindCompass Final Demo\\",frameborder:\\"0\\",allow:\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\",allowfullscreen:!0,style:{marginBottom:\\"2rem\\"}}),`\\n`,(0,i.jsxs)(e.h1,{id:\\"summary\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#summary\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Summary\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"MindCompass is a mixed reality app designed to help kids practice immersive, guided meditation in the comfort of their own home, promoting independence and healthy emotional regulation. Users are guided by friendly creatures and transported to mystical lands, earning rewards for building good habits. This project was started as part of Stanford\\\\u2019s Introduction to Human Computer Interaction (CS 147) class in Fall of 2023, in which our group won the \\\\u201CBest Overall Project\\\\u201D and \\\\u201CMost Novel\\\\u201D awards for our efforts.\\"}),`\\n`,(0,i.jsxs)(e.p,{children:[\\"Check out our full design process at our project \\",(0,i.jsx)(e.a,{href:\\"https://hci.stanford.edu/courses/cs147/2023/au/projects/AccessingHealthcare/MindCompass/\\",children:\\"website\\"}),\\" including needfinding, experience prototyping, annotated task flows, low-fi user testing, heuristic evaluation, our hi-fi Unity demo, and more! The entire process from start to finish is also documented in our \\",(0,i.jsx)(e.a,{href:\\"https://docs.google.com/document/d/1Mk08d4agAaUTJZbPJzXVYzkIkdLyrchrN66KLymyBYI/edit?usp=sharing\\",children:\\"final report\\"}),\\".\\"]}),`\\n`,(0,i.jsxs)(e.h1,{id:\\"needfinding--solution-brainstorming\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#needfinding--solution-brainstorming\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Needfinding + Solution Brainstorming\\"]}),`\\n`,(0,i.jsx)(e.p,{children:`Our problem scope initially focused on parenting and caretaking in general. We conducted two rounds of needfinding interviews, recruiting a total of 6 participants, all parents who spanned a range of occupations and child raising experience.\\nWhen interviewing participants, we focused on a few themed guiding questions. A few examples are listed below:`}),`\\n`,(0,i.jsxs)(e.ul,{children:[`\\n`,(0,i.jsx)(e.li,{children:\\"Roadblocks: What roadblocks hamper(ed) you from performing your childcare duties to the fullest?\\"}),`\\n`,(0,i.jsx)(e.li,{children:\\"Trust: How did you navigate different sources of advice and learn what to trust?\\"}),`\\n`,(0,i.jsx)(e.li,{children:\\"Support: What kind of support network was available to you when raising a child?\\"}),`\\n`]}),`\\n`,(0,i.jsxs)(e.h2,{id:\\"result-synthesis\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#result-synthesis\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Result Synthesis\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"Our needfinding interviews were incredibly insightful in highlighting key areas and issues faced by parents and caretakers. For each interviewee, we generated individual empathy maps (what the interviewee says, thinks, does, and feels) and noted key quotes and insights from their interview. After repeating this process for each interviewee, we identified several overarching themes:\\"}),`\\n`,(0,i.jsxs)(e.ul,{children:[`\\n`,(0,i.jsx)(e.li,{children:\\"Self-discovery: allowing for self-discovery is just as (if not more) important than outside advice during the parenting process.\\"}),`\\n`,(0,i.jsx)(e.li,{children:\\"Support: a strong support group and network of peers can be critical for relieving stress during parenting.\\"}),`\\n`,(0,i.jsx)(e.li,{children:\\"No generic solutions: you can\\\\u2019t bundle all \\\\u201Cchildcare\\\\u201D together, even if kids are seemingly similar in age; each kid is different from each other.\\"}),`\\n`,(0,i.jsx)(e.li,{children:\\"Pressure: New parents will weigh every decision with a lot of anxiety in order to try to be perfect.\\"}),`\\n`]}),`\\n`,(0,i.jsxs)(e.h2,{id:\\"povs--how-might-wes\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#povs--how-might-wes\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"POVs & How Might Wes\\"]}),`\\n`,(0,i.jsx)(e.p,{children:`As a team, we developed POV (point of view) statements based on two of our strongest interviews and generated \\\\u201CHow Might We\\\\u201D (HMW) statements to brainstorm possible pain points that could be addressed by expanded solutions.\\nWe brainstormed 10-15 solutions for each HMW statement.`}),`\\n`,(0,i.jsx)(e.p,{children:\\"Below is a small sample of our findings from initial needfinding interviews and our generation of potential \\\\u201Chow might we\\\\u201D statements and solutions.\\"}),`\\n`,(0,i.jsx)(\\"img\\",{src:\\"/mindcompass/mindcompass-1.png\\",alt:\\"lo-fi sketch\\",width:\\"100%\\"}),`\\n`,(0,i.jsx)(\\"img\\",{src:\\"/mindcompass/mindcompass-2.png\\",alt:\\"lo-fi sketch\\",width:\\"100%\\"}),`\\n`,(0,i.jsx)(\\"img\\",{src:\\"/mindcompass/mindcompass-3.png\\",alt:\\"lo-fi sketch\\",width:\\"100%\\"}),`\\n`,(0,i.jsxs)(e.h2,{id:\\"experience-prototypes\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#experience-prototypes\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Experience prototypes\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"We next created 3 different experience prototypes, one corresponding to each of our 3 top solutions. These prototypes were designed to test assumptions we are making about our users and their behavior (not any UI or design itself). We narrowed down on assumptions that if false, would cause our idea to fail and brainstormed lightweight tests to validate those critical assumptions.\\"}),`\\n`,(0,i.jsx)(e.p,{children:\\"Below is a description of 1 of the 3 prototypes:\\"}),`\\n`,(0,i.jsxs)(e.ul,{children:[`\\n`,(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:\\"Assumption\\"}),\\": parents need help gamifying individual parenting tasks\\"]}),`\\n`,(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:\\"Set up\\"}),\\": 1) Conversation about their general parenting experience, 2) Sketchnoting exercise - interviewees were shown an AI-generated photo of a common gamified parenting task (\\\\u201CHere comes the airplane!\\\\u201D)\\"]}),`\\n`,(0,i.jsxs)(e.li,{children:[(0,i.jsx)(e.strong,{children:\\"Questions\\"}),\': \\"What does this photo remind you of?\\", \\"Do you similarly gamify tasks with your child?\\", \\"What\\\\u2019s a hard childcare task for you? Try to gamify it.\\"\']}),`\\n`]}),`\\n`,(0,i.jsx)(\\"img\\",{src:\\"/mindcompass/experience-prototypes.png\\",alt:\\"lo-fi sketch\\",width:\\"100%\\"}),`\\n`,(0,i.jsx)(e.p,{children:\\"Takeaways from this prototype were:\\"}),`\\n`,(0,i.jsxs)(e.ul,{children:[`\\n`,(0,i.jsx)(e.li,{children:\\"Parents lack awareness of how to gamify certain tasks\\"}),`\\n`,(0,i.jsx)(e.li,{children:\\"Children have more energy and imagination than their parents\\"}),`\\n`,(0,i.jsxs)(e.li,{children:[\\"Parents \\",(0,i.jsx)(e.em,{children:\\"are\\"}),\\" searching for answers, but don\\\\u2019t know what works for their child\\"]}),`\\n`,(0,i.jsx)(e.li,{children:\\"Decreasing the cognitive stress of seeking better ways to gamify tasks empowers both the parent and child\\"}),`\\n`]}),`\\n`,(0,i.jsxs)(e.h2,{id:\\"final-solution\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#final-solution\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Final Solution\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\\"Following our experience prototyping results and reflecting on our past interviews, we decided to narrow down on the question: How can we meet the needs of parents and kids by helping kids regulate their emotions in a way that is appealing to their childish imagination and sense of wonder?\\"}),`\\n`,(0,i.jsx)(e.p,{children:\\"While the question may seem to differ quite a bit from our prior focus on addressing parenting needs alone, our gamification experience prototype and our previous needfinding chat with an elementary school teacher, heavily influenced our new direction. She emphasized the importance of teaching kids emotional control, especially after the COVID-19 pandemic, going out of her way to show us various materials and resources she relies on to support the students she teaches. Our focus on supporting a fundamental need of children also directly removes the emotional burden and stress placed on parents to teach such skills. By supporting young children, we also support new parents.\\"}),`\\n`,(0,i.jsxs)(e.p,{children:[`Thus, our final solution resulted in the following:\\n`,(0,i.jsx)(e.strong,{children:\\"Using gamification in mixed reality to guide children through the practice of meditation, simultaneously promoting independence and healthy emotional regulation.\\"})]}),`\\n`,(0,i.jsxs)(e.h2,{id:\\"initial-lo-fi-prototype\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#initial-lo-fi-prototype\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Initial Lo-fi Prototype\\"]}),`\\n`,(0,i.jsx)(e.p,{children:\'We created a paper lo-fi prototype of our XR screens walking through selection and experience of a meditation activity. We tested this prototype on multiple participants in person, having them point to various parts of the \\"screens\\" and narrate their thinking aloud.\'}),`\\n`,(0,i.jsx)(\\"img\\",{src:\\"/mindcompass/mindcompass-4.png\\",alt:\\"lo-fi sketch\\",width:\\"100%\\"}),`\\n`,(0,i.jsx)(\\"img\\",{src:\\"/mindcompass/mindcompass-5.jpeg\\",alt:\\"lo-fi sketch\\",width:\\"100%\\"}),`\\n`,(0,i.jsxs)(e.h1,{id:\\"figma-medium-fi-prototype\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#figma-medium-fi-prototype\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Figma Medium-Fi Prototype\\"]}),`\\n`,(0,i.jsxs)(e.p,{children:[`Below are a sample of the XR screens I designed in Figma including onboarding, meditation customization settings, experience completion, and rewards.\\nCheck out our interactive Figma demo `,(0,i.jsx)(e.a,{href:\\"https://www.figma.com/proto/KpWBUwZBQ54ysAo6pPKiqA/MindCompass-Med-fi-Prototype?type=design&node-id=102-9885&t=Jgl4SeAPzJmJYQNc-1&scaling=min-zoom&page-id=0%3A1&starting-point-node-id=102%3A9885&show-proto-sidebar=1\\",children:\\"here\\"}),\\". Note that some aspects of the designs below were updated after Figma prototyping and were incorporated later in the actual hi-fi demo (below).\\"]}),`\\n`,(0,i.jsx)(\\"img\\",{src:\\"/mindcompass/mindcompass-6.png\\",alt:\\"lo-fi sketch\\",width:\\"100%\\"}),`\\n`,(0,i.jsxs)(e.h1,{id:\\"unity-hi-fi-demo-video\\",children:[(0,i.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#unity-hi-fi-demo-video\\",children:(0,i.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Unity Hi-Fi Demo Video\\"]}),`\\n`,(0,i.jsxs)(e.p,{children:[`Our final application was developed in Unity for the Meta Quest 3. We used a Figma to Unity plugin to directly import the 2D walkthrough and rewards screens. We used Eleven Labs to generate the audio for the meditation narrative. Upon completing the onboarding, users are transported to a calming grassy landscape where a friendly panda named \\"Pando\\" guides them through the experience.\\nCheck out the video demo `,(0,i.jsx)(e.a,{href:\\"https://www.youtube.com/watch?v=Kt_2jgPzT4I\\",children:\\"here\\"}),\\"!\\"]})]})}function v(n={}){let{wrapper:e}=n.components||{};return e?(0,i.jsx)(e,Object.assign({},n,{children:(0,i.jsx)(c,n)})):c(n)}var x=v;return b(N);})();\\n;return Component;"},"_id":"projects/mindcompass.mdx","_raw":{"sourceFilePath":"projects/mindcompass.mdx","sourceFileName":"mindcompass.mdx","sourceFileDir":"projects","contentType":"mdx","flattenedPath":"projects/mindcompass"},"type":"Project","path":"projects/mindcompass","slug":"mindcompass"},{"published":true,"title":"Mindstorm","description":"A personalized wellness companion to help you find the calm in your storm.","date":"2023-02-01T00:00:00.000Z","repository":"ckunchur/mindstorm","videoDemo":"https://www.youtube.com/watch?v=8SBlpKvKBGE","tools":["Figma","ReactNative","OpenAI"],"displayDate":"Winter 2024","category":"Mobile","body":{"raw":"\\n\\n<img src=\\"/mindstorm/mindstorm-poster.png\\" alt=\\"mindstorm poster\\" style={{ borderRadius: \'1rem\', margin: \'2rem 0\' }} />\\n\\n\\n## Mission\\n<div className=\\"flex flex-col md:flex-row items-start gap-8 mt-4\\">\\n  <p className=\\"flex-1\\">\\n    Your journey to well-being is unique. Your support should be too. We utilize personalized LLM companions and goal-oriented pipelines to build emotional resilience, discover healthy habits, and empower you on your path to a happier, healthier you.\\n  </p>\\n\\n  <iframe\\n    className=\\"w-1/3\\"\\n    height=\\"400\\"\\n    src=\\"https://www.youtube.com/embed/8SBlpKvKBGE\\"\\n    title=\\"MindStorm Final Demo\\"\\n    frameBorder=\\"0\\"\\n    allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\"\\n    allowFullScreen\\n  />\\n</div>\\n## Inspiration\\n\\nThis project was inspired by a recent study published in Nature [1], which investigated the potential of artificial intelligence (AI) for mental health interventions. The study explored the use of large language models (LLMs) to provide emotional support and personalized guidance to individuals. The findings highlighted the promise of AI chatbots in:\\n\\n- Enhancing accessibility: Offering 24/7 support, overcoming geographical limitations and potentially reducing therapy costs.\\n- Promoting self-discovery: Enabling users to gain insights into their emotions and thought patterns through reflection and journaling prompts.\\n- Providing personalized support: Tailoring responses and guidance based on user input, creating a more individualized experience compared to traditional therapy resources.\\n\\n([1] Loneliness and suicide mitigation for students using GPT3-enabled chatbots: [Nature Article](https://www.nature.com/articles/s44184-023-00047-6#Sec10))\\n\\nWe believe that Mindstorm can build upon this research by developing a comprehensive AI-powered mental wellness companion. Our app aims to address the limitations identified in the study, such as:\\n\\n- **Limited emotional understanding:** By incorporating advanced emotional recognition techniques, we can create AI companions that can better respond to user emotions, addressing people who might not want to see a real therapist/had bad experiences with therapy.\\n- **Focus on short-term interactions:** We aim to provide long-term support through features like weekly analysis and goal-setting tools.\\n\\nOur vision is to create a user-friendly and accessible tool that empowers individuals on their journey towards mental well-being.\\n\\n## Problem\\n\\nMental health concerns are prevalent, with anxiety affecting over 264 million people globally, according to WHO. Yet, accessing effective care remains a challenge. Cost, scheduling difficulties, and social stigma create major barriers.\\n\\nThe result? People struggling the most are often the least likely to seek help. Over 54% of adults with mental illness don’t seek treatment (WHO). This creates a vicious cycle, impacting their overall well-being, relationships, and physical health.\\n\\nMindstorm is here to break free from the limitations of traditional therapy. We offer personalized, accessible support through an accessible on-the-go app. Forget one-size-fits-all: we use LLMs with specialized chatbots tailored to address specific needs: ADHD, depression, anxiety, and productivity goals. The App Store and GPT Store are flooded with generic mental wellness chatbots. We offer something fundamentally different: precise support tailored to your specific needs.\\n\\n## Differentiators\\n\\nWe have a pipeline and a specialized companion for every need, with long-term adaptive memory. With RAG-powered personalization, the companion you talk to analyzes your chat history, experiences, struggles, and preferences, allowing it to provide targeted support that resonates with your unique needs.\\n\\nUnlike generic apps with a one-size-fits-all therapist, Mindstorm evolves with you. It’s your personalized mental health partner, offering ongoing guidance and a safe space to work towards your goals.\\n\\n## Usage\\n\\nOur user flow is simple — journal and reflect on your day, and choose to chat from your entry with a recommended companion based on what we detected from your needs. Over time, you can check your weekly insights to make sense of your trends and emotional landscape.\\n<img src=\\"/mindstorm/mindstorm-journaling.png\\" alt=\\"mindstorm poster\\" style={{ borderRadius: \'1rem\', margin: \'2rem 0\' }} />\\n\\n## Current Features\\n\\n### Specialized Companions:\\n<img src=\\"/mindstorm/mindstorm-characters.png\\" alt=\\"mindstorm poster\\" style={{  margin: \'2rem 0\' }} />\\n\\n- **Lyra, Your Anxiety Coach:** Feeling the pressure rise? Lyra detects your anxiety in real-time and provides personalized stress management techniques tailored to your preferences. Uncover the \'why\' behind your thoughts and understand the root causes of your recurring patterns, tailored to your unique experiences.\\n- **Nimbus, Your Productivity Partner:** Drowning in a sea of thoughts and to-dos? Nimbus helps you conquer mental clutter by organizing tasks and prioritizing your workload. Reduce overwhelm, regain control, and achieve more with Nimbus by your side.\\n- **Solara, Your Reflective Buddy:** Need to step back and see the bigger picture? Solara utilizes your past entries to guide you in high-level reflection. Explore patterns, gain insights, and make informed changes for a better tomorrow with Solara\'s insightful prompts.\\n\\nThese specialized companions work together to create a personalized support system that adapts to your evolving needs.\\n\\n### Adaptive Long-Term Memory:\\n<div className=\\"flex flex-col md:flex-row items-start gap-8 mt-4\\">\\n<div>\\nImagine a companion that not only listens, but truly remembers. Unlike basic chatbots, Mindstorm utilizes RAG (Retrieval-Augmented Generation) to:\\n\\n- **Personalize Your Experience:** We analyze your interactions, preferences, and past entries to tailor responses and support that hits home for you.\\n- **Dynamic Learning:** Our adaptive memory continuously evolves alongside you. As you share your experiences and emotions, your companion gains a deeper understanding of your unique needs.\\n- **Precise Therapy:** By understanding your individual patterns and triggers, we can provide targeted therapy suggestions and coping mechanisms that are effective for you.\\n\\nThink of it as a conversation that deepens over time. The more you interact with Mindstorm, the better your AI companion can support you on your path to optimal well-being.\\n</div>\\n<img src=\\"/mindstorm/mindstorm-chat.png\\" alt=\\"mindstorm insights page\\" style={{  margin: \'2rem 0\' }} width=\\"35%\\"/>\\n\\n</div>\\n### Weekly Insights:\\n\\n<img src=\\"/mindstorm/mindstorm-insights.png\\" alt=\\"mindstorm insights page\\" style={{  margin: \'2rem 0\' }} width=\\"60%\\" />\\n\\n- **Weekly Summary**\\n    - Reflect & Reconnect: Gain a clear view of your week\'s entries with our concise summary. This easy-to-read snapshot helps you connect the dots and identify recurring themes in your thoughts and emotions.\\n- **Mood Trends**\\n    - Uncover Your Emotional Landscape: Dive deeper with our mood trend analysis. By understanding your emotional patterns throughout the week, you can gain valuable insights and personalize self-care strategies for greater well-being.\\n- **Brain Real Estate**\\n    - Know What Occupies Your Mind: Ever feel overwhelmed by swirling thoughts? \\"Brain Real Estate\\" reveals the topics that occupy your mind the most. This self-discovery tool empowers you to prioritize what matters most and focus on areas that need your attention.\\n\\n","code":"var Component=(()=>{var h=Object.create;var o=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var m=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,g=Object.prototype.hasOwnProperty;var y=(i,e)=>()=>(e||i((e={exports:{}}).exports,e),e.exports),f=(i,e)=>{for(var r in e)o(i,r,{get:e[r],enumerable:!0})},s=(i,e,r,a)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let t of m(e))!g.call(i,t)&&t!==r&&o(i,t,{get:()=>e[t],enumerable:!(a=p(e,t))||a.enumerable});return i};var w=(i,e,r)=>(r=i!=null?h(u(i)):{},s(e||!i||!i.__esModule?o(r,\\"default\\",{value:i,enumerable:!0}):r,i)),b=i=>s(o({},\\"__esModule\\",{value:!0}),i);var c=y((L,l)=>{l.exports=_jsx_runtime});var x={};f(x,{default:()=>N,frontmatter:()=>v});var n=w(c()),v={title:\\"Mindstorm\\",description:\\"A personalized wellness companion to help you find the calm in your storm.\\",date:\\"2023-02-01\\",displayDate:\\"Winter 2024\\",published:!0,repository:\\"ckunchur/mindstorm\\",videoDemo:\\"https://www.youtube.com/watch?v=8SBlpKvKBGE\\",category:\\"Mobile\\",tools:[\\"Figma\\",\\"ReactNative\\",\\"OpenAI\\"]};function d(i){let e=Object.assign({h2:\\"h2\\",a:\\"a\\",span:\\"span\\",p:\\"p\\",ul:\\"ul\\",li:\\"li\\",strong:\\"strong\\",h3:\\"h3\\"},i.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(\\"img\\",{src:\\"/mindstorm/mindstorm-poster.png\\",alt:\\"mindstorm poster\\",style:{borderRadius:\\"1rem\\",margin:\\"2rem 0\\"}}),`\\n`,(0,n.jsxs)(e.h2,{id:\\"mission\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#mission\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Mission\\"]}),`\\n`,(0,n.jsxs)(\\"div\\",{className:\\"flex flex-col md:flex-row items-start gap-8 mt-4\\",children:[(0,n.jsx)(\\"p\\",{className:\\"flex-1\\",children:(0,n.jsx)(e.p,{children:\\"Your journey to well-being is unique. Your support should be too. We utilize personalized LLM companions and goal-oriented pipelines to build emotional resilience, discover healthy habits, and empower you on your path to a happier, healthier you.\\"})}),(0,n.jsx)(\\"iframe\\",{className:\\"w-1/3\\",height:\\"400\\",src:\\"https://www.youtube.com/embed/8SBlpKvKBGE\\",title:\\"MindStorm Final Demo\\",frameBorder:\\"0\\",allow:\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\\",allowFullScreen:!0})]}),`\\n`,(0,n.jsxs)(e.h2,{id:\\"inspiration\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#inspiration\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Inspiration\\"]}),`\\n`,(0,n.jsx)(e.p,{children:\\"This project was inspired by a recent study published in Nature [1], which investigated the potential of artificial intelligence (AI) for mental health interventions. The study explored the use of large language models (LLMs) to provide emotional support and personalized guidance to individuals. The findings highlighted the promise of AI chatbots in:\\"}),`\\n`,(0,n.jsxs)(e.ul,{children:[`\\n`,(0,n.jsx)(e.li,{children:\\"Enhancing accessibility: Offering 24/7 support, overcoming geographical limitations and potentially reducing therapy costs.\\"}),`\\n`,(0,n.jsx)(e.li,{children:\\"Promoting self-discovery: Enabling users to gain insights into their emotions and thought patterns through reflection and journaling prompts.\\"}),`\\n`,(0,n.jsx)(e.li,{children:\\"Providing personalized support: Tailoring responses and guidance based on user input, creating a more individualized experience compared to traditional therapy resources.\\"}),`\\n`]}),`\\n`,(0,n.jsxs)(e.p,{children:[\\"([1] Loneliness and suicide mitigation for students using GPT3-enabled chatbots: \\",(0,n.jsx)(e.a,{href:\\"https://www.nature.com/articles/s44184-023-00047-6#Sec10\\",children:\\"Nature Article\\"}),\\")\\"]}),`\\n`,(0,n.jsx)(e.p,{children:\\"We believe that Mindstorm can build upon this research by developing a comprehensive AI-powered mental wellness companion. Our app aims to address the limitations identified in the study, such as:\\"}),`\\n`,(0,n.jsxs)(e.ul,{children:[`\\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\\"Limited emotional understanding:\\"}),\\" By incorporating advanced emotional recognition techniques, we can create AI companions that can better respond to user emotions, addressing people who might not want to see a real therapist/had bad experiences with therapy.\\"]}),`\\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\\"Focus on short-term interactions:\\"}),\\" We aim to provide long-term support through features like weekly analysis and goal-setting tools.\\"]}),`\\n`]}),`\\n`,(0,n.jsx)(e.p,{children:\\"Our vision is to create a user-friendly and accessible tool that empowers individuals on their journey towards mental well-being.\\"}),`\\n`,(0,n.jsxs)(e.h2,{id:\\"problem\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#problem\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Problem\\"]}),`\\n`,(0,n.jsx)(e.p,{children:\\"Mental health concerns are prevalent, with anxiety affecting over 264 million people globally, according to WHO. Yet, accessing effective care remains a challenge. Cost, scheduling difficulties, and social stigma create major barriers.\\"}),`\\n`,(0,n.jsx)(e.p,{children:\\"The result? People struggling the most are often the least likely to seek help. Over 54% of adults with mental illness don\\\\u2019t seek treatment (WHO). This creates a vicious cycle, impacting their overall well-being, relationships, and physical health.\\"}),`\\n`,(0,n.jsx)(e.p,{children:\\"Mindstorm is here to break free from the limitations of traditional therapy. We offer personalized, accessible support through an accessible on-the-go app. Forget one-size-fits-all: we use LLMs with specialized chatbots tailored to address specific needs: ADHD, depression, anxiety, and productivity goals. The App Store and GPT Store are flooded with generic mental wellness chatbots. We offer something fundamentally different: precise support tailored to your specific needs.\\"}),`\\n`,(0,n.jsxs)(e.h2,{id:\\"differentiators\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#differentiators\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Differentiators\\"]}),`\\n`,(0,n.jsx)(e.p,{children:\\"We have a pipeline and a specialized companion for every need, with long-term adaptive memory. With RAG-powered personalization, the companion you talk to analyzes your chat history, experiences, struggles, and preferences, allowing it to provide targeted support that resonates with your unique needs.\\"}),`\\n`,(0,n.jsx)(e.p,{children:\\"Unlike generic apps with a one-size-fits-all therapist, Mindstorm evolves with you. It\\\\u2019s your personalized mental health partner, offering ongoing guidance and a safe space to work towards your goals.\\"}),`\\n`,(0,n.jsxs)(e.h2,{id:\\"usage\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#usage\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Usage\\"]}),`\\n`,(0,n.jsx)(e.p,{children:\\"Our user flow is simple \\\\u2014 journal and reflect on your day, and choose to chat from your entry with a recommended companion based on what we detected from your needs. Over time, you can check your weekly insights to make sense of your trends and emotional landscape.\\"}),`\\n`,(0,n.jsx)(\\"img\\",{src:\\"/mindstorm/mindstorm-journaling.png\\",alt:\\"mindstorm poster\\",style:{borderRadius:\\"1rem\\",margin:\\"2rem 0\\"}}),`\\n`,(0,n.jsxs)(e.h2,{id:\\"current-features\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#current-features\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Current Features\\"]}),`\\n`,(0,n.jsxs)(e.h3,{id:\\"specialized-companions\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#specialized-companions\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Specialized Companions:\\"]}),`\\n`,(0,n.jsx)(\\"img\\",{src:\\"/mindstorm/mindstorm-characters.png\\",alt:\\"mindstorm poster\\",style:{margin:\\"2rem 0\\"}}),`\\n`,(0,n.jsxs)(e.ul,{children:[`\\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\\"Lyra, Your Anxiety Coach:\\"}),\\" Feeling the pressure rise? Lyra detects your anxiety in real-time and provides personalized stress management techniques tailored to your preferences. Uncover the \'why\' behind your thoughts and understand the root causes of your recurring patterns, tailored to your unique experiences.\\"]}),`\\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\\"Nimbus, Your Productivity Partner:\\"}),\\" Drowning in a sea of thoughts and to-dos? Nimbus helps you conquer mental clutter by organizing tasks and prioritizing your workload. Reduce overwhelm, regain control, and achieve more with Nimbus by your side.\\"]}),`\\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\\"Solara, Your Reflective Buddy:\\"}),\\" Need to step back and see the bigger picture? Solara utilizes your past entries to guide you in high-level reflection. Explore patterns, gain insights, and make informed changes for a better tomorrow with Solara\'s insightful prompts.\\"]}),`\\n`]}),`\\n`,(0,n.jsx)(e.p,{children:\\"These specialized companions work together to create a personalized support system that adapts to your evolving needs.\\"}),`\\n`,(0,n.jsxs)(e.h3,{id:\\"adaptive-long-term-memory\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#adaptive-long-term-memory\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Adaptive Long-Term Memory:\\"]}),`\\n`,(0,n.jsxs)(\\"div\\",{className:\\"flex flex-col md:flex-row items-start gap-8 mt-4\\",children:[(0,n.jsxs)(\\"div\\",{children:[(0,n.jsx)(e.p,{children:\\"Imagine a companion that not only listens, but truly remembers. Unlike basic chatbots, Mindstorm utilizes RAG (Retrieval-Augmented Generation) to:\\"}),(0,n.jsxs)(e.ul,{children:[`\\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\\"Personalize Your Experience:\\"}),\\" We analyze your interactions, preferences, and past entries to tailor responses and support that hits home for you.\\"]}),`\\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\\"Dynamic Learning:\\"}),\\" Our adaptive memory continuously evolves alongside you. As you share your experiences and emotions, your companion gains a deeper understanding of your unique needs.\\"]}),`\\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\\"Precise Therapy:\\"}),\\" By understanding your individual patterns and triggers, we can provide targeted therapy suggestions and coping mechanisms that are effective for you.\\"]}),`\\n`]}),(0,n.jsx)(e.p,{children:\\"Think of it as a conversation that deepens over time. The more you interact with Mindstorm, the better your AI companion can support you on your path to optimal well-being.\\"})]}),(0,n.jsx)(\\"img\\",{src:\\"/mindstorm/mindstorm-chat.png\\",alt:\\"mindstorm insights page\\",style:{margin:\\"2rem 0\\"},width:\\"35%\\"})]}),`\\n`,(0,n.jsxs)(e.h3,{id:\\"weekly-insights\\",children:[(0,n.jsx)(e.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#weekly-insights\\",children:(0,n.jsx)(e.span,{className:\\"icon icon-link\\"})}),\\"Weekly Insights:\\"]}),`\\n`,(0,n.jsx)(\\"img\\",{src:\\"/mindstorm/mindstorm-insights.png\\",alt:\\"mindstorm insights page\\",style:{margin:\\"2rem 0\\"},width:\\"60%\\"}),`\\n`,(0,n.jsxs)(e.ul,{children:[`\\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\\"Weekly Summary\\"}),`\\n`,(0,n.jsxs)(e.ul,{children:[`\\n`,(0,n.jsx)(e.li,{children:\\"Reflect & Reconnect: Gain a clear view of your week\'s entries with our concise summary. This easy-to-read snapshot helps you connect the dots and identify recurring themes in your thoughts and emotions.\\"}),`\\n`]}),`\\n`]}),`\\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\\"Mood Trends\\"}),`\\n`,(0,n.jsxs)(e.ul,{children:[`\\n`,(0,n.jsx)(e.li,{children:\\"Uncover Your Emotional Landscape: Dive deeper with our mood trend analysis. By understanding your emotional patterns throughout the week, you can gain valuable insights and personalize self-care strategies for greater well-being.\\"}),`\\n`]}),`\\n`]}),`\\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.strong,{children:\\"Brain Real Estate\\"}),`\\n`,(0,n.jsxs)(e.ul,{children:[`\\n`,(0,n.jsx)(e.li,{children:\'Know What Occupies Your Mind: Ever feel overwhelmed by swirling thoughts? \\"Brain Real Estate\\" reveals the topics that occupy your mind the most. This self-discovery tool empowers you to prioritize what matters most and focus on areas that need your attention.\'}),`\\n`]}),`\\n`]}),`\\n`]})]})}function k(i={}){let{wrapper:e}=i.components||{};return e?(0,n.jsx)(e,Object.assign({},i,{children:(0,n.jsx)(d,i)})):d(i)}var N=k;return b(x);})();\\n;return Component;"},"_id":"projects/mindstorm.mdx","_raw":{"sourceFilePath":"projects/mindstorm.mdx","sourceFileName":"mindstorm.mdx","sourceFileDir":"projects","contentType":"mdx","flattenedPath":"projects/mindstorm"},"type":"Project","path":"projects/mindstorm","slug":"mindstorm"},{"published":true,"title":"Pediatric Apple Watch Study","description":"Evaluating use of Apple Watch for detecting arrhythmias in pediatric patients.","date":"2023-02-01T00:00:00.000Z","tools":["Swift","React","Firebase"],"displayDate":"Winter 2023","category":"Mobile","body":{"raw":"# Summary\\n\\nIn Winter 2023, I was the project manager and lead developer for a Stanford group project (CS 342) to evaluate Apple Watch arrhythmia diagnosis abilities in children. We developed a full stack iOS app to streamline collection of Apple Watch ECG tracings and symptoms information and automate upload of the data to a secure research server. To aid in clinician ability to draw insights from the data, I initiated development of a React web dashboard to display ECG recording data and created an graph visualization module for raw ECG voltage data.\\n# Software Architecture\\n\\nOur application framework integrated the Stanford Spezi template application (learn more [here](https://spezi.stanford.edu/)), Apple\'s HealthKit, and Google Firebase for backend storage of ECG recordings as FHIR standard JSON files.\\n<img src=\\"/paws/paws-1.png\\" alt=\\"PAWS software architecture\\" style={{ borderRadius: \'1rem\', margin: \'2rem 0\' }} />\\n\\n# iOS Screens\\nSelected screens from the iOS application including: 1) landing screen, 2) patient home page showing last recorded ECG, and 3) record of uploaded ECGs + indication of upload status\\n<img src=\\"/paws/paws-2.png\\" alt=\\"ios screen of PAWS mobile app\\" style={{ borderRadius: \'1rem\', margin: \'2rem 0\' }} />\\n\\n# Web Application Screens\\nBelow are screens for retrieving patient information and visualizing individual ECG voltage data along with associated data collected by the Apple Watch (heart rate, diagnosis, patient report symptoms, etc). Options are also available for physicians to assign their opinions on the diagnosis and quality of Apple Watch tracing. Note: patient names blurred out for privacy.\\n<img src=\\"/paws/paws-3.png\\" alt=\\"web app screen showing patient list\\" style={{ borderRadius: \'1rem\', margin: \'2rem 0\' }} />\\n<img src=\\"/paws/paws-4.jpg\\" alt=\\"web app screen showing ECG analysis\\" style={{ borderRadius: \'1rem\', margin: \'2rem 0\' }} />\\n","code":"var Component=(()=>{var dr=Object.create;var F=Object.defineProperty;var pr=Object.getOwnPropertyDescriptor;var mr=Object.getOwnPropertyNames;var br=Object.getPrototypeOf,hr=Object.prototype.hasOwnProperty;var X=(u,t)=>()=>(t||u((t={exports:{}}).exports,t),t.exports),vr=(u,t)=>{for(var v in t)F(u,v,{get:t[v],enumerable:!0})},Re=(u,t,v,y)=>{if(t&&typeof t==\\"object\\"||typeof t==\\"function\\")for(let g of mr(t))!hr.call(u,g)&&g!==v&&F(u,g,{get:()=>t[g],enumerable:!(y=pr(t,g))||y.enumerable});return u};var _r=(u,t,v)=>(v=u!=null?dr(br(u)):{},Re(t||!u||!u.__esModule?F(v,\\"default\\",{value:u,enumerable:!0}):v,u)),gr=u=>Re(F({},\\"__esModule\\",{value:!0}),u);var je=X((jr,xe)=>{xe.exports=React});var ke=X(q=>{\\"use strict\\";(function(){\\"use strict\\";var u=je(),t=Symbol.for(\\"react.element\\"),v=Symbol.for(\\"react.portal\\"),y=Symbol.for(\\"react.fragment\\"),g=Symbol.for(\\"react.strict_mode\\"),H=Symbol.for(\\"react.profiler\\"),J=Symbol.for(\\"react.provider\\"),Z=Symbol.for(\\"react.context\\"),C=Symbol.for(\\"react.forward_ref\\"),U=Symbol.for(\\"react.suspense\\"),W=Symbol.for(\\"react.suspense_list\\"),T=Symbol.for(\\"react.memo\\"),I=Symbol.for(\\"react.lazy\\"),Te=Symbol.for(\\"react.offscreen\\"),Q=Symbol.iterator,Oe=\\"@@iterator\\";function De(e){if(e===null||typeof e!=\\"object\\")return null;var r=Q&&e[Q]||e[Oe];return typeof r==\\"function\\"?r:null}var R=u.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;function p(e){{for(var r=arguments.length,n=new Array(r>1?r-1:0),a=1;a<r;a++)n[a-1]=arguments[a];Pe(\\"error\\",e,n)}}function Pe(e,r,n){{var a=R.ReactDebugCurrentFrame,c=a.getStackAddendum();c!==\\"\\"&&(r+=\\"%s\\",n=n.concat([c]));var s=n.map(function(i){return String(i)});s.unshift(\\"Warning: \\"+r),Function.prototype.apply.call(console[e],console,s)}}var Ae=!1,Fe=!1,Ue=!1,We=!1,Ie=!1,ee;ee=Symbol.for(\\"react.module.reference\\");function Ye(e){return!!(typeof e==\\"string\\"||typeof e==\\"function\\"||e===y||e===H||Ie||e===g||e===U||e===W||We||e===Te||Ae||Fe||Ue||typeof e==\\"object\\"&&e!==null&&(e.$$typeof===I||e.$$typeof===T||e.$$typeof===J||e.$$typeof===Z||e.$$typeof===C||e.$$typeof===ee||e.getModuleId!==void 0))}function $e(e,r,n){var a=e.displayName;if(a)return a;var c=r.displayName||r.name||\\"\\";return c!==\\"\\"?n+\\"(\\"+c+\\")\\":n}function re(e){return e.displayName||\\"Context\\"}function _(e){if(e==null)return null;if(typeof e.tag==\\"number\\"&&p(\\"Received an unexpected object in getComponentNameFromType(). This is likely a bug in React. Please file an issue.\\"),typeof e==\\"function\\")return e.displayName||e.name||null;if(typeof e==\\"string\\")return e;switch(e){case y:return\\"Fragment\\";case v:return\\"Portal\\";case H:return\\"Profiler\\";case g:return\\"StrictMode\\";case U:return\\"Suspense\\";case W:return\\"SuspenseList\\"}if(typeof e==\\"object\\")switch(e.$$typeof){case Z:var r=e;return re(r)+\\".Consumer\\";case J:var n=e;return re(n._context)+\\".Provider\\";case C:return $e(e,e.render,\\"ForwardRef\\");case T:var a=e.displayName||null;return a!==null?a:_(e.type)||\\"Memo\\";case I:{var c=e,s=c._payload,i=c._init;try{return _(i(s))}catch{return null}}}return null}var E=Object.assign,k=0,ne,ae,te,oe,ie,ce,se;function le(){}le.__reactDisabledLog=!0;function Le(){{if(k===0){ne=console.log,ae=console.info,te=console.warn,oe=console.error,ie=console.group,ce=console.groupCollapsed,se=console.groupEnd;var e={configurable:!0,enumerable:!0,value:le,writable:!0};Object.defineProperties(console,{info:e,log:e,warn:e,error:e,group:e,groupCollapsed:e,groupEnd:e})}k++}}function Me(){{if(k--,k===0){var e={configurable:!0,enumerable:!0,writable:!0};Object.defineProperties(console,{log:E({},e,{value:ne}),info:E({},e,{value:ae}),warn:E({},e,{value:te}),error:E({},e,{value:oe}),group:E({},e,{value:ie}),groupCollapsed:E({},e,{value:ce}),groupEnd:E({},e,{value:se})})}k<0&&p(\\"disabledDepth fell below zero. This is a bug in React. Please file an issue.\\")}}var Y=R.ReactCurrentDispatcher,$;function O(e,r,n){{if($===void 0)try{throw Error()}catch(c){var a=c.stack.trim().match(/\\\\n( *(at )?)/);$=a&&a[1]||\\"\\"}return`\\n`+$+e}}var L=!1,D;{var Ve=typeof WeakMap==\\"function\\"?WeakMap:Map;D=new Ve}function ue(e,r){if(!e||L)return\\"\\";{var n=D.get(e);if(n!==void 0)return n}var a;L=!0;var c=Error.prepareStackTrace;Error.prepareStackTrace=void 0;var s;s=Y.current,Y.current=null,Le();try{if(r){var i=function(){throw Error()};if(Object.defineProperty(i.prototype,\\"props\\",{set:function(){throw Error()}}),typeof Reflect==\\"object\\"&&Reflect.construct){try{Reflect.construct(i,[])}catch(b){a=b}Reflect.construct(e,[],i)}else{try{i.call()}catch(b){a=b}e.call(i.prototype)}}else{try{throw Error()}catch(b){a=b}e()}}catch(b){if(b&&a&&typeof b.stack==\\"string\\"){for(var o=b.stack.split(`\\n`),m=a.stack.split(`\\n`),f=o.length-1,d=m.length-1;f>=1&&d>=0&&o[f]!==m[d];)d--;for(;f>=1&&d>=0;f--,d--)if(o[f]!==m[d]){if(f!==1||d!==1)do if(f--,d--,d<0||o[f]!==m[d]){var h=`\\n`+o[f].replace(\\" at new \\",\\" at \\");return e.displayName&&h.includes(\\"<anonymous>\\")&&(h=h.replace(\\"<anonymous>\\",e.displayName)),typeof e==\\"function\\"&&D.set(e,h),h}while(f>=1&&d>=0);break}}}finally{L=!1,Y.current=s,Me(),Error.prepareStackTrace=c}var j=e?e.displayName||e.name:\\"\\",w=j?O(j):\\"\\";return typeof e==\\"function\\"&&D.set(e,w),w}function Ge(e,r,n){return ue(e,!1)}function ze(e){var r=e.prototype;return!!(r&&r.isReactComponent)}function P(e,r,n){if(e==null)return\\"\\";if(typeof e==\\"function\\")return ue(e,ze(e));if(typeof e==\\"string\\")return O(e);switch(e){case U:return O(\\"Suspense\\");case W:return O(\\"SuspenseList\\")}if(typeof e==\\"object\\")switch(e.$$typeof){case C:return Ge(e.render);case T:return P(e.type,r,n);case I:{var a=e,c=a._payload,s=a._init;try{return P(s(c),r,n)}catch{}}}return\\"\\"}var S=Object.prototype.hasOwnProperty,fe={},de=R.ReactDebugCurrentFrame;function A(e){if(e){var r=e._owner,n=P(e.type,e._source,r?r.type:null);de.setExtraStackFrame(n)}else de.setExtraStackFrame(null)}function Be(e,r,n,a,c){{var s=Function.call.bind(S);for(var i in e)if(s(e,i)){var o=void 0;try{if(typeof e[i]!=\\"function\\"){var m=Error((a||\\"React class\\")+\\": \\"+n+\\" type `\\"+i+\\"` is invalid; it must be a function, usually from the `prop-types` package, but received `\\"+typeof e[i]+\\"`.This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.\\");throw m.name=\\"Invariant Violation\\",m}o=e[i](r,i,a,n,null,\\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\\")}catch(f){o=f}o&&!(o instanceof Error)&&(A(c),p(\\"%s: type specification of %s `%s` is invalid; the type checker function must return `null` or an `Error` but returned a %s. You may have forgotten to pass an argument to the type checker creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and shape all require an argument).\\",a||\\"React class\\",n,i,typeof o),A(null)),o instanceof Error&&!(o.message in fe)&&(fe[o.message]=!0,A(c),p(\\"Failed %s type: %s\\",n,o.message),A(null))}}}var Ke=Array.isArray;function M(e){return Ke(e)}function Xe(e){{var r=typeof Symbol==\\"function\\"&&Symbol.toStringTag,n=r&&e[Symbol.toStringTag]||e.constructor.name||\\"Object\\";return n}}function qe(e){try{return pe(e),!1}catch{return!0}}function pe(e){return\\"\\"+e}function me(e){if(qe(e))return p(\\"The provided key is an unsupported type %s. This value must be coerced to a string before before using it here.\\",Xe(e)),pe(e)}var N=R.ReactCurrentOwner,He={key:!0,ref:!0,__self:!0,__source:!0},be,he,V;V={};function Je(e){if(S.call(e,\\"ref\\")){var r=Object.getOwnPropertyDescriptor(e,\\"ref\\").get;if(r&&r.isReactWarning)return!1}return e.ref!==void 0}function Ze(e){if(S.call(e,\\"key\\")){var r=Object.getOwnPropertyDescriptor(e,\\"key\\").get;if(r&&r.isReactWarning)return!1}return e.key!==void 0}function Qe(e,r){if(typeof e.ref==\\"string\\"&&N.current&&r&&N.current.stateNode!==r){var n=_(N.current.type);V[n]||(p(\'Component \\"%s\\" contains the string ref \\"%s\\". Support for string refs will be removed in a future major release. This case cannot be automatically converted to an arrow function. We ask you to manually fix this case by using useRef() or createRef() instead. Learn more about using refs safely here: https://reactjs.org/link/strict-mode-string-ref\',_(N.current.type),e.ref),V[n]=!0)}}function er(e,r){{var n=function(){be||(be=!0,p(\\"%s: `key` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\\",r))};n.isReactWarning=!0,Object.defineProperty(e,\\"key\\",{get:n,configurable:!0})}}function rr(e,r){{var n=function(){he||(he=!0,p(\\"%s: `ref` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\\",r))};n.isReactWarning=!0,Object.defineProperty(e,\\"ref\\",{get:n,configurable:!0})}}var nr=function(e,r,n,a,c,s,i){var o={$$typeof:t,type:e,key:r,ref:n,props:i,_owner:s};return o._store={},Object.defineProperty(o._store,\\"validated\\",{configurable:!1,enumerable:!1,writable:!0,value:!1}),Object.defineProperty(o,\\"_self\\",{configurable:!1,enumerable:!1,writable:!1,value:a}),Object.defineProperty(o,\\"_source\\",{configurable:!1,enumerable:!1,writable:!1,value:c}),Object.freeze&&(Object.freeze(o.props),Object.freeze(o)),o};function ar(e,r,n,a,c){{var s,i={},o=null,m=null;n!==void 0&&(me(n),o=\\"\\"+n),Ze(r)&&(me(r.key),o=\\"\\"+r.key),Je(r)&&(m=r.ref,Qe(r,c));for(s in r)S.call(r,s)&&!He.hasOwnProperty(s)&&(i[s]=r[s]);if(e&&e.defaultProps){var f=e.defaultProps;for(s in f)i[s]===void 0&&(i[s]=f[s])}if(o||m){var d=typeof e==\\"function\\"?e.displayName||e.name||\\"Unknown\\":e;o&&er(i,d),m&&rr(i,d)}return nr(e,o,m,c,a,N.current,i)}}var G=R.ReactCurrentOwner,ve=R.ReactDebugCurrentFrame;function x(e){if(e){var r=e._owner,n=P(e.type,e._source,r?r.type:null);ve.setExtraStackFrame(n)}else ve.setExtraStackFrame(null)}var z;z=!1;function B(e){return typeof e==\\"object\\"&&e!==null&&e.$$typeof===t}function _e(){{if(G.current){var e=_(G.current.type);if(e)return`\\n\\nCheck the render method of \\\\``+e+\\"`.\\"}return\\"\\"}}function tr(e){{if(e!==void 0){var r=e.fileName.replace(/^.*[\\\\\\\\\\\\/]/,\\"\\"),n=e.lineNumber;return`\\n\\nCheck your code at `+r+\\":\\"+n+\\".\\"}return\\"\\"}}var ge={};function or(e){{var r=_e();if(!r){var n=typeof e==\\"string\\"?e:e.displayName||e.name;n&&(r=`\\n\\nCheck the top-level render call using <`+n+\\">.\\")}return r}}function ye(e,r){{if(!e._store||e._store.validated||e.key!=null)return;e._store.validated=!0;var n=or(r);if(ge[n])return;ge[n]=!0;var a=\\"\\";e&&e._owner&&e._owner!==G.current&&(a=\\" It was passed a child from \\"+_(e._owner.type)+\\".\\"),x(e),p(\'Each child in a list should have a unique \\"key\\" prop.%s%s See https://reactjs.org/link/warning-keys for more information.\',n,a),x(null)}}function Ee(e,r){{if(typeof e!=\\"object\\")return;if(M(e))for(var n=0;n<e.length;n++){var a=e[n];B(a)&&ye(a,r)}else if(B(e))e._store&&(e._store.validated=!0);else if(e){var c=De(e);if(typeof c==\\"function\\"&&c!==e.entries)for(var s=c.call(e),i;!(i=s.next()).done;)B(i.value)&&ye(i.value,r)}}}function ir(e){{var r=e.type;if(r==null||typeof r==\\"string\\")return;var n;if(typeof r==\\"function\\")n=r.propTypes;else if(typeof r==\\"object\\"&&(r.$$typeof===C||r.$$typeof===T))n=r.propTypes;else return;if(n){var a=_(r);Be(n,e.props,\\"prop\\",a,e)}else if(r.PropTypes!==void 0&&!z){z=!0;var c=_(r);p(\\"Component %s declared `PropTypes` instead of `propTypes`. Did you misspell the property assignment?\\",c||\\"Unknown\\")}typeof r.getDefaultProps==\\"function\\"&&!r.getDefaultProps.isReactClassApproved&&p(\\"getDefaultProps is only used on classic React.createClass definitions. Use a static property named `defaultProps` instead.\\")}}function cr(e){{for(var r=Object.keys(e.props),n=0;n<r.length;n++){var a=r[n];if(a!==\\"children\\"&&a!==\\"key\\"){x(e),p(\\"Invalid prop `%s` supplied to `React.Fragment`. React.Fragment can only have `key` and `children` props.\\",a),x(null);break}}e.ref!==null&&(x(e),p(\\"Invalid attribute `ref` supplied to `React.Fragment`.\\"),x(null))}}var we={};function sr(e,r,n,a,c,s){{var i=Ye(e);if(!i){var o=\\"\\";(e===void 0||typeof e==\\"object\\"&&e!==null&&Object.keys(e).length===0)&&(o+=\\" You likely forgot to export your component from the file it\'s defined in, or you might have mixed up default and named imports.\\");var m=tr(c);m?o+=m:o+=_e();var f;e===null?f=\\"null\\":M(e)?f=\\"array\\":e!==void 0&&e.$$typeof===t?(f=\\"<\\"+(_(e.type)||\\"Unknown\\")+\\" />\\",o=\\" Did you accidentally export a JSX literal instead of a component?\\"):f=typeof e,p(\\"React.jsx: type is invalid -- expected a string (for built-in components) or a class/function (for composite components) but got: %s.%s\\",f,o)}var d=ar(e,r,n,c,s);if(d==null)return d;if(i){var h=r.children;if(h!==void 0)if(a)if(M(h)){for(var j=0;j<h.length;j++)Ee(h[j],e);Object.freeze&&Object.freeze(h)}else p(\\"React.jsx: Static children should always be an array. You are likely explicitly calling React.jsxs or React.jsxDEV. Use the Babel transform instead.\\");else Ee(h,e)}if(S.call(r,\\"key\\")){var w=_(e),b=Object.keys(r).filter(function(fr){return fr!==\\"key\\"}),K=b.length>0?\\"{key: someKey, \\"+b.join(\\": ..., \\")+\\": ...}\\":\\"{key: someKey}\\";if(!we[w+K]){var ur=b.length>0?\\"{\\"+b.join(\\": ..., \\")+\\": ...}\\":\\"{}\\";p(`A props object containing a \\"key\\" prop is being spread into JSX:\\n  let props = %s;\\n  <%s {...props} />\\nReact keys must be passed directly to JSX without using spread:\\n  let props = %s;\\n  <%s key={someKey} {...props} />`,K,w,ur,w),we[w+K]=!0}}return e===y?cr(d):ir(d),d}}var lr=sr;q.Fragment=y,q.jsxDEV=lr})()});var Ne=X((Sr,Se)=>{\\"use strict\\";Se.exports=ke()});var Rr={};vr(Rr,{default:()=>wr,frontmatter:()=>yr});var l=_r(Ne()),yr={title:\\"Pediatric Apple Watch Study\\",description:\\"Evaluating use of Apple Watch for detecting arrhythmias in pediatric patients.\\",date:\\"2023-02-01\\",displayDate:\\"Winter 2023\\",published:!0,category:\\"Mobile\\",tools:[\\"Swift\\",\\"React\\",\\"Firebase\\"]};function Ce(u){let t=Object.assign({h1:\\"h1\\",a:\\"a\\",span:\\"span\\",p:\\"p\\"},u.components);return(0,l.jsxDEV)(l.Fragment,{children:[(0,l.jsxDEV)(t.h1,{id:\\"summary\\",children:[(0,l.jsxDEV)(t.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#summary\\",children:(0,l.jsxDEV)(t.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\"},this),\\"Summary\\"]},void 0,!0,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:13,columnNumber:1},this),`\\n`,(0,l.jsxDEV)(t.p,{children:\\"In Winter 2023, I was the project manager and lead developer for a Stanford group project (CS 342) to evaluate Apple Watch arrhythmia diagnosis abilities in children. We developed a full stack iOS app to streamline collection of Apple Watch ECG tracings and symptoms information and automate upload of the data to a secure research server. To aid in clinician ability to draw insights from the data, I initiated development of a React web dashboard to display ECG recording data and created an graph visualization module for raw ECG voltage data.\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:15,columnNumber:1},this),`\\n`,(0,l.jsxDEV)(t.h1,{id:\\"software-architecture\\",children:[(0,l.jsxDEV)(t.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#software-architecture\\",children:(0,l.jsxDEV)(t.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\"},this),\\"Software Architecture\\"]},void 0,!0,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:16,columnNumber:1},this),`\\n`,(0,l.jsxDEV)(t.p,{children:[\\"Our application framework integrated the Stanford Spezi template application (learn more \\",(0,l.jsxDEV)(t.a,{href:\\"https://spezi.stanford.edu/\\",children:\\"here\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:18,columnNumber:90},this),\\"), Apple\'s HealthKit, and Google Firebase for backend storage of ECG recordings as FHIR standard JSON files.\\"]},void 0,!0,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:18,columnNumber:1},this),`\\n`,(0,l.jsxDEV)(\\"img\\",{src:\\"/paws/paws-1.png\\",alt:\\"PAWS software architecture\\",style:{borderRadius:\\"1rem\\",margin:\\"2rem 0\\"}},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:19,columnNumber:1},this),`\\n`,(0,l.jsxDEV)(t.h1,{id:\\"ios-screens\\",children:[(0,l.jsxDEV)(t.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#ios-screens\\",children:(0,l.jsxDEV)(t.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\"},this),\\"iOS Screens\\"]},void 0,!0,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:21,columnNumber:1},this),`\\n`,(0,l.jsxDEV)(t.p,{children:\\"Selected screens from the iOS application including: 1) landing screen, 2) patient home page showing last recorded ECG, and 3) record of uploaded ECGs + indication of upload status\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:22,columnNumber:1},this),`\\n`,(0,l.jsxDEV)(\\"img\\",{src:\\"/paws/paws-2.png\\",alt:\\"ios screen of PAWS mobile app\\",style:{borderRadius:\\"1rem\\",margin:\\"2rem 0\\"}},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:23,columnNumber:1},this),`\\n`,(0,l.jsxDEV)(t.h1,{id:\\"web-application-screens\\",children:[(0,l.jsxDEV)(t.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#web-application-screens\\",children:(0,l.jsxDEV)(t.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\"},this),\\"Web Application Screens\\"]},void 0,!0,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:25,columnNumber:1},this),`\\n`,(0,l.jsxDEV)(t.p,{children:\\"Below are screens for retrieving patient information and visualizing individual ECG voltage data along with associated data collected by the Apple Watch (heart rate, diagnosis, patient report symptoms, etc). Options are also available for physicians to assign their opinions on the diagnosis and quality of Apple Watch tracing. Note: patient names blurred out for privacy.\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:26,columnNumber:1},this),`\\n`,(0,l.jsxDEV)(\\"img\\",{src:\\"/paws/paws-3.png\\",alt:\\"web app screen showing patient list\\",style:{borderRadius:\\"1rem\\",margin:\\"2rem 0\\"}},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:27,columnNumber:1},this),`\\n`,(0,l.jsxDEV)(\\"img\\",{src:\\"/paws/paws-4.jpg\\",alt:\\"web app screen showing ECG analysis\\",style:{borderRadius:\\"1rem\\",margin:\\"2rem 0\\"}},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:28,columnNumber:1},this)]},void 0,!0,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\",lineNumber:1,columnNumber:1},this)}function Er(u={}){let{wrapper:t}=u.components||{};return t?(0,l.jsxDEV)(t,Object.assign({},u,{children:(0,l.jsxDEV)(Ce,u,void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\"},this)}),void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-2d7cbcb6-8cc8-4724-aec0-ace3a413a184.mdx\\"},this):Ce(u)}var wr=Er;return gr(Rr);})();\\n/*! Bundled license information:\\n\\nreact/cjs/react-jsx-dev-runtime.development.js:\\n  (**\\n   * @license React\\n   * react-jsx-dev-runtime.development.js\\n   *\\n   * Copyright (c) Facebook, Inc. and its affiliates.\\n   *\\n   * This source code is licensed under the MIT license found in the\\n   * LICENSE file in the root directory of this source tree.\\n   *)\\n*/\\n;return Component;"},"_id":"projects/paws.mdx","_raw":{"sourceFilePath":"projects/paws.mdx","sourceFileName":"paws.mdx","sourceFileDir":"projects","contentType":"mdx","flattenedPath":"projects/paws"},"type":"Project","path":"projects/paws","slug":"paws"},{"published":true,"title":"Spotify Redesign","description":"A design concept for a new Spotify \\"Social\\" feature.","date":"2023-03-01T00:00:00.000Z","tools":["Figma"],"displayDate":"Spring 2023","category":"Mobile","body":{"raw":"\\n# Summary\\n\\nAs part of my Intro to UI/UX Design class (CS 91SI), we learned best practices for designing effective user interfaces and experiences through topics including design patterns, interaction patterns, consistent decision making, design systems and UI models, and animation prototyping. With hands on projects in Figma, we redesigned features of Spotify and followed a PRD for suggestion of a new feature to boost Spotify Premium membership.\\n\\n# Stage 1: Screen Recreation\\nBelow are Figma recreations of a Spotify home page and \\"liked songs\\" page, created using autolayout boxes and Spotify typography/iconography.\\n\\n<img src=\\"/spotify/spotify-1.png\\" alt=\\"figma screenshot of spotify recreation\\" style={{ borderRadius: \'1rem\', margin: \'2rem 0\' }} />\\n\\n# Stage 2: Spotify Social\\nBelow is my suggested design for a new \\"Spotify Social\\" feature – an integrated space that lets users have more defined profiles, boost interaction with friends, more easily compare listening activity, and compete for awards and rankings. The Social \\"Home\\" page displays listening activity for friends, a leaderboard based on listening activity, and Blend – a more prominent/visible version of the current Spotify blend feature. Users also have a more detailed \\"Social\\" profile page and a new Social \\"Awards\\" page that gamifies the listening experience.\\n<img src=\\"/spotify/spotify-2.png\\" alt=\\"figma screenshots of new social feature for Spotify\\" style={{ borderRadius: \'1rem\', margin: \'2rem 0\' }} />\\n","code":"var Component=(()=>{var dr=Object.create;var A=Object.defineProperty;var pr=Object.getOwnPropertyDescriptor;var mr=Object.getOwnPropertyNames;var vr=Object.getPrototypeOf,hr=Object.prototype.hasOwnProperty;var q=(u,a)=>()=>(a||u((a={exports:{}}).exports,a),a.exports),br=(u,a)=>{for(var b in a)A(u,b,{get:a[b],enumerable:!0})},we=(u,a,b,_)=>{if(a&&typeof a==\\"object\\"||typeof a==\\"function\\")for(let y of mr(a))!hr.call(u,y)&&y!==b&&A(u,y,{get:()=>a[y],enumerable:!(_=pr(a,y))||_.enumerable});return u};var gr=(u,a,b)=>(b=u!=null?dr(vr(u)):{},we(a||!u||!u.__esModule?A(b,\\"default\\",{value:u,enumerable:!0}):b,u)),yr=u=>we(A({},\\"__esModule\\",{value:!0}),u);var xe=q((xr,Se)=>{Se.exports=React});var je=q(z=>{\\"use strict\\";(function(){\\"use strict\\";var u=xe(),a=Symbol.for(\\"react.element\\"),b=Symbol.for(\\"react.portal\\"),_=Symbol.for(\\"react.fragment\\"),y=Symbol.for(\\"react.strict_mode\\"),H=Symbol.for(\\"react.profiler\\"),J=Symbol.for(\\"react.provider\\"),Z=Symbol.for(\\"react.context\\"),C=Symbol.for(\\"react.forward_ref\\"),U=Symbol.for(\\"react.suspense\\"),I=Symbol.for(\\"react.suspense_list\\"),D=Symbol.for(\\"react.memo\\"),W=Symbol.for(\\"react.lazy\\"),De=Symbol.for(\\"react.offscreen\\"),Q=Symbol.iterator,Oe=\\"@@iterator\\";function Pe(e){if(e===null||typeof e!=\\"object\\")return null;var r=Q&&e[Q]||e[Oe];return typeof r==\\"function\\"?r:null}var w=u.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;function p(e){{for(var r=arguments.length,n=new Array(r>1?r-1:0),t=1;t<r;t++)n[t-1]=arguments[t];Ne(\\"error\\",e,n)}}function Ne(e,r,n){{var t=w.ReactDebugCurrentFrame,s=t.getStackAddendum();s!==\\"\\"&&(r+=\\"%s\\",n=n.concat([s]));var c=n.map(function(i){return String(i)});c.unshift(\\"Warning: \\"+r),Function.prototype.apply.call(console[e],console,c)}}var Fe=!1,Ae=!1,Ue=!1,Ie=!1,We=!1,ee;ee=Symbol.for(\\"react.module.reference\\");function Ye(e){return!!(typeof e==\\"string\\"||typeof e==\\"function\\"||e===_||e===H||We||e===y||e===U||e===I||Ie||e===De||Fe||Ae||Ue||typeof e==\\"object\\"&&e!==null&&(e.$$typeof===W||e.$$typeof===D||e.$$typeof===J||e.$$typeof===Z||e.$$typeof===C||e.$$typeof===ee||e.getModuleId!==void 0))}function $e(e,r,n){var t=e.displayName;if(t)return t;var s=r.displayName||r.name||\\"\\";return s!==\\"\\"?n+\\"(\\"+s+\\")\\":n}function re(e){return e.displayName||\\"Context\\"}function g(e){if(e==null)return null;if(typeof e.tag==\\"number\\"&&p(\\"Received an unexpected object in getComponentNameFromType(). This is likely a bug in React. Please file an issue.\\"),typeof e==\\"function\\")return e.displayName||e.name||null;if(typeof e==\\"string\\")return e;switch(e){case _:return\\"Fragment\\";case b:return\\"Portal\\";case H:return\\"Profiler\\";case y:return\\"StrictMode\\";case U:return\\"Suspense\\";case I:return\\"SuspenseList\\"}if(typeof e==\\"object\\")switch(e.$$typeof){case Z:var r=e;return re(r)+\\".Consumer\\";case J:var n=e;return re(n._context)+\\".Provider\\";case C:return $e(e,e.render,\\"ForwardRef\\");case D:var t=e.displayName||null;return t!==null?t:g(e.type)||\\"Memo\\";case W:{var s=e,c=s._payload,i=s._init;try{return g(i(c))}catch{return null}}}return null}var E=Object.assign,j=0,ne,te,ae,oe,ie,se,ce;function ue(){}ue.__reactDisabledLog=!0;function Me(){{if(j===0){ne=console.log,te=console.info,ae=console.warn,oe=console.error,ie=console.group,se=console.groupCollapsed,ce=console.groupEnd;var e={configurable:!0,enumerable:!0,value:ue,writable:!0};Object.defineProperties(console,{info:e,log:e,warn:e,error:e,group:e,groupCollapsed:e,groupEnd:e})}j++}}function Le(){{if(j--,j===0){var e={configurable:!0,enumerable:!0,writable:!0};Object.defineProperties(console,{log:E({},e,{value:ne}),info:E({},e,{value:te}),warn:E({},e,{value:ae}),error:E({},e,{value:oe}),group:E({},e,{value:ie}),groupCollapsed:E({},e,{value:se}),groupEnd:E({},e,{value:ce})})}j<0&&p(\\"disabledDepth fell below zero. This is a bug in React. Please file an issue.\\")}}var Y=w.ReactCurrentDispatcher,$;function O(e,r,n){{if($===void 0)try{throw Error()}catch(s){var t=s.stack.trim().match(/\\\\n( *(at )?)/);$=t&&t[1]||\\"\\"}return`\\n`+$+e}}var M=!1,P;{var Ve=typeof WeakMap==\\"function\\"?WeakMap:Map;P=new Ve}function le(e,r){if(!e||M)return\\"\\";{var n=P.get(e);if(n!==void 0)return n}var t;M=!0;var s=Error.prepareStackTrace;Error.prepareStackTrace=void 0;var c;c=Y.current,Y.current=null,Me();try{if(r){var i=function(){throw Error()};if(Object.defineProperty(i.prototype,\\"props\\",{set:function(){throw Error()}}),typeof Reflect==\\"object\\"&&Reflect.construct){try{Reflect.construct(i,[])}catch(v){t=v}Reflect.construct(e,[],i)}else{try{i.call()}catch(v){t=v}e.call(i.prototype)}}else{try{throw Error()}catch(v){t=v}e()}}catch(v){if(v&&t&&typeof v.stack==\\"string\\"){for(var o=v.stack.split(`\\n`),m=t.stack.split(`\\n`),l=o.length-1,f=m.length-1;l>=1&&f>=0&&o[l]!==m[f];)f--;for(;l>=1&&f>=0;l--,f--)if(o[l]!==m[f]){if(l!==1||f!==1)do if(l--,f--,f<0||o[l]!==m[f]){var h=`\\n`+o[l].replace(\\" at new \\",\\" at \\");return e.displayName&&h.includes(\\"<anonymous>\\")&&(h=h.replace(\\"<anonymous>\\",e.displayName)),typeof e==\\"function\\"&&P.set(e,h),h}while(l>=1&&f>=0);break}}}finally{M=!1,Y.current=c,Le(),Error.prepareStackTrace=s}var x=e?e.displayName||e.name:\\"\\",R=x?O(x):\\"\\";return typeof e==\\"function\\"&&P.set(e,R),R}function Be(e,r,n){return le(e,!1)}function Ke(e){var r=e.prototype;return!!(r&&r.isReactComponent)}function N(e,r,n){if(e==null)return\\"\\";if(typeof e==\\"function\\")return le(e,Ke(e));if(typeof e==\\"string\\")return O(e);switch(e){case U:return O(\\"Suspense\\");case I:return O(\\"SuspenseList\\")}if(typeof e==\\"object\\")switch(e.$$typeof){case C:return Be(e.render);case D:return N(e.type,r,n);case W:{var t=e,s=t._payload,c=t._init;try{return N(c(s),r,n)}catch{}}}return\\"\\"}var T=Object.prototype.hasOwnProperty,fe={},de=w.ReactDebugCurrentFrame;function F(e){if(e){var r=e._owner,n=N(e.type,e._source,r?r.type:null);de.setExtraStackFrame(n)}else de.setExtraStackFrame(null)}function Xe(e,r,n,t,s){{var c=Function.call.bind(T);for(var i in e)if(c(e,i)){var o=void 0;try{if(typeof e[i]!=\\"function\\"){var m=Error((t||\\"React class\\")+\\": \\"+n+\\" type `\\"+i+\\"` is invalid; it must be a function, usually from the `prop-types` package, but received `\\"+typeof e[i]+\\"`.This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.\\");throw m.name=\\"Invariant Violation\\",m}o=e[i](r,i,t,n,null,\\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\\")}catch(l){o=l}o&&!(o instanceof Error)&&(F(s),p(\\"%s: type specification of %s `%s` is invalid; the type checker function must return `null` or an `Error` but returned a %s. You may have forgotten to pass an argument to the type checker creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and shape all require an argument).\\",t||\\"React class\\",n,i,typeof o),F(null)),o instanceof Error&&!(o.message in fe)&&(fe[o.message]=!0,F(s),p(\\"Failed %s type: %s\\",n,o.message),F(null))}}}var Ge=Array.isArray;function L(e){return Ge(e)}function qe(e){{var r=typeof Symbol==\\"function\\"&&Symbol.toStringTag,n=r&&e[Symbol.toStringTag]||e.constructor.name||\\"Object\\";return n}}function ze(e){try{return pe(e),!1}catch{return!0}}function pe(e){return\\"\\"+e}function me(e){if(ze(e))return p(\\"The provided key is an unsupported type %s. This value must be coerced to a string before before using it here.\\",qe(e)),pe(e)}var k=w.ReactCurrentOwner,He={key:!0,ref:!0,__self:!0,__source:!0},ve,he,V;V={};function Je(e){if(T.call(e,\\"ref\\")){var r=Object.getOwnPropertyDescriptor(e,\\"ref\\").get;if(r&&r.isReactWarning)return!1}return e.ref!==void 0}function Ze(e){if(T.call(e,\\"key\\")){var r=Object.getOwnPropertyDescriptor(e,\\"key\\").get;if(r&&r.isReactWarning)return!1}return e.key!==void 0}function Qe(e,r){if(typeof e.ref==\\"string\\"&&k.current&&r&&k.current.stateNode!==r){var n=g(k.current.type);V[n]||(p(\'Component \\"%s\\" contains the string ref \\"%s\\". Support for string refs will be removed in a future major release. This case cannot be automatically converted to an arrow function. We ask you to manually fix this case by using useRef() or createRef() instead. Learn more about using refs safely here: https://reactjs.org/link/strict-mode-string-ref\',g(k.current.type),e.ref),V[n]=!0)}}function er(e,r){{var n=function(){ve||(ve=!0,p(\\"%s: `key` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\\",r))};n.isReactWarning=!0,Object.defineProperty(e,\\"key\\",{get:n,configurable:!0})}}function rr(e,r){{var n=function(){he||(he=!0,p(\\"%s: `ref` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\\",r))};n.isReactWarning=!0,Object.defineProperty(e,\\"ref\\",{get:n,configurable:!0})}}var nr=function(e,r,n,t,s,c,i){var o={$$typeof:a,type:e,key:r,ref:n,props:i,_owner:c};return o._store={},Object.defineProperty(o._store,\\"validated\\",{configurable:!1,enumerable:!1,writable:!0,value:!1}),Object.defineProperty(o,\\"_self\\",{configurable:!1,enumerable:!1,writable:!1,value:t}),Object.defineProperty(o,\\"_source\\",{configurable:!1,enumerable:!1,writable:!1,value:s}),Object.freeze&&(Object.freeze(o.props),Object.freeze(o)),o};function tr(e,r,n,t,s){{var c,i={},o=null,m=null;n!==void 0&&(me(n),o=\\"\\"+n),Ze(r)&&(me(r.key),o=\\"\\"+r.key),Je(r)&&(m=r.ref,Qe(r,s));for(c in r)T.call(r,c)&&!He.hasOwnProperty(c)&&(i[c]=r[c]);if(e&&e.defaultProps){var l=e.defaultProps;for(c in l)i[c]===void 0&&(i[c]=l[c])}if(o||m){var f=typeof e==\\"function\\"?e.displayName||e.name||\\"Unknown\\":e;o&&er(i,f),m&&rr(i,f)}return nr(e,o,m,s,t,k.current,i)}}var B=w.ReactCurrentOwner,be=w.ReactDebugCurrentFrame;function S(e){if(e){var r=e._owner,n=N(e.type,e._source,r?r.type:null);be.setExtraStackFrame(n)}else be.setExtraStackFrame(null)}var K;K=!1;function X(e){return typeof e==\\"object\\"&&e!==null&&e.$$typeof===a}function ge(){{if(B.current){var e=g(B.current.type);if(e)return`\\n\\nCheck the render method of \\\\``+e+\\"`.\\"}return\\"\\"}}function ar(e){{if(e!==void 0){var r=e.fileName.replace(/^.*[\\\\\\\\\\\\/]/,\\"\\"),n=e.lineNumber;return`\\n\\nCheck your code at `+r+\\":\\"+n+\\".\\"}return\\"\\"}}var ye={};function or(e){{var r=ge();if(!r){var n=typeof e==\\"string\\"?e:e.displayName||e.name;n&&(r=`\\n\\nCheck the top-level render call using <`+n+\\">.\\")}return r}}function _e(e,r){{if(!e._store||e._store.validated||e.key!=null)return;e._store.validated=!0;var n=or(r);if(ye[n])return;ye[n]=!0;var t=\\"\\";e&&e._owner&&e._owner!==B.current&&(t=\\" It was passed a child from \\"+g(e._owner.type)+\\".\\"),S(e),p(\'Each child in a list should have a unique \\"key\\" prop.%s%s See https://reactjs.org/link/warning-keys for more information.\',n,t),S(null)}}function Ee(e,r){{if(typeof e!=\\"object\\")return;if(L(e))for(var n=0;n<e.length;n++){var t=e[n];X(t)&&_e(t,r)}else if(X(e))e._store&&(e._store.validated=!0);else if(e){var s=Pe(e);if(typeof s==\\"function\\"&&s!==e.entries)for(var c=s.call(e),i;!(i=c.next()).done;)X(i.value)&&_e(i.value,r)}}}function ir(e){{var r=e.type;if(r==null||typeof r==\\"string\\")return;var n;if(typeof r==\\"function\\")n=r.propTypes;else if(typeof r==\\"object\\"&&(r.$$typeof===C||r.$$typeof===D))n=r.propTypes;else return;if(n){var t=g(r);Xe(n,e.props,\\"prop\\",t,e)}else if(r.PropTypes!==void 0&&!K){K=!0;var s=g(r);p(\\"Component %s declared `PropTypes` instead of `propTypes`. Did you misspell the property assignment?\\",s||\\"Unknown\\")}typeof r.getDefaultProps==\\"function\\"&&!r.getDefaultProps.isReactClassApproved&&p(\\"getDefaultProps is only used on classic React.createClass definitions. Use a static property named `defaultProps` instead.\\")}}function sr(e){{for(var r=Object.keys(e.props),n=0;n<r.length;n++){var t=r[n];if(t!==\\"children\\"&&t!==\\"key\\"){S(e),p(\\"Invalid prop `%s` supplied to `React.Fragment`. React.Fragment can only have `key` and `children` props.\\",t),S(null);break}}e.ref!==null&&(S(e),p(\\"Invalid attribute `ref` supplied to `React.Fragment`.\\"),S(null))}}var Re={};function cr(e,r,n,t,s,c){{var i=Ye(e);if(!i){var o=\\"\\";(e===void 0||typeof e==\\"object\\"&&e!==null&&Object.keys(e).length===0)&&(o+=\\" You likely forgot to export your component from the file it\'s defined in, or you might have mixed up default and named imports.\\");var m=ar(s);m?o+=m:o+=ge();var l;e===null?l=\\"null\\":L(e)?l=\\"array\\":e!==void 0&&e.$$typeof===a?(l=\\"<\\"+(g(e.type)||\\"Unknown\\")+\\" />\\",o=\\" Did you accidentally export a JSX literal instead of a component?\\"):l=typeof e,p(\\"React.jsx: type is invalid -- expected a string (for built-in components) or a class/function (for composite components) but got: %s.%s\\",l,o)}var f=tr(e,r,n,s,c);if(f==null)return f;if(i){var h=r.children;if(h!==void 0)if(t)if(L(h)){for(var x=0;x<h.length;x++)Ee(h[x],e);Object.freeze&&Object.freeze(h)}else p(\\"React.jsx: Static children should always be an array. You are likely explicitly calling React.jsxs or React.jsxDEV. Use the Babel transform instead.\\");else Ee(h,e)}if(T.call(r,\\"key\\")){var R=g(e),v=Object.keys(r).filter(function(fr){return fr!==\\"key\\"}),G=v.length>0?\\"{key: someKey, \\"+v.join(\\": ..., \\")+\\": ...}\\":\\"{key: someKey}\\";if(!Re[R+G]){var lr=v.length>0?\\"{\\"+v.join(\\": ..., \\")+\\": ...}\\":\\"{}\\";p(`A props object containing a \\"key\\" prop is being spread into JSX:\\n  let props = %s;\\n  <%s {...props} />\\nReact keys must be passed directly to JSX without using spread:\\n  let props = %s;\\n  <%s key={someKey} {...props} />`,G,R,lr,R),Re[R+G]=!0}}return e===_?sr(f):ir(f),f}}var ur=cr;z.Fragment=_,z.jsxDEV=ur})()});var ke=q((Tr,Te)=>{\\"use strict\\";Te.exports=je()});var wr={};br(wr,{default:()=>Rr,frontmatter:()=>_r});var d=gr(ke()),_r={title:\\"Spotify Redesign\\",description:\'A design concept for a new Spotify \\"Social\\" feature.\',date:\\"2023-03-01\\",displayDate:\\"Spring 2023\\",published:!0,category:\\"Mobile\\",tools:[\\"Figma\\"]};function Ce(u){let a=Object.assign({h1:\\"h1\\",a:\\"a\\",span:\\"span\\",p:\\"p\\"},u.components);return(0,d.jsxDEV)(d.Fragment,{children:[(0,d.jsxDEV)(a.h1,{id:\\"summary\\",children:[(0,d.jsxDEV)(a.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#summary\\",children:(0,d.jsxDEV)(a.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\"},this),\\"Summary\\"]},void 0,!0,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\",lineNumber:14,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(a.p,{children:\\"As part of my Intro to UI/UX Design class (CS 91SI), we learned best practices for designing effective user interfaces and experiences through topics including design patterns, interaction patterns, consistent decision making, design systems and UI models, and animation prototyping. With hands on projects in Figma, we redesigned features of Spotify and followed a PRD for suggestion of a new feature to boost Spotify Premium membership.\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\",lineNumber:16,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(a.h1,{id:\\"stage-1-screen-recreation\\",children:[(0,d.jsxDEV)(a.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#stage-1-screen-recreation\\",children:(0,d.jsxDEV)(a.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\"},this),\\"Stage 1: Screen Recreation\\"]},void 0,!0,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\",lineNumber:18,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(a.p,{children:\'Below are Figma recreations of a Spotify home page and \\"liked songs\\" page, created using autolayout boxes and Spotify typography/iconography.\'},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\",lineNumber:19,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(\\"img\\",{src:\\"/spotify/spotify-1.png\\",alt:\\"figma screenshot of spotify recreation\\",style:{borderRadius:\\"1rem\\",margin:\\"2rem 0\\"}},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\",lineNumber:21,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(a.h1,{id:\\"stage-2-spotify-social\\",children:[(0,d.jsxDEV)(a.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#stage-2-spotify-social\\",children:(0,d.jsxDEV)(a.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\"},this),\\"Stage 2: Spotify Social\\"]},void 0,!0,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\",lineNumber:23,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(a.p,{children:\'Below is my suggested design for a new \\"Spotify Social\\" feature \\\\u2013 an integrated space that lets users have more defined profiles, boost interaction with friends, more easily compare listening activity, and compete for awards and rankings. The Social \\"Home\\" page displays listening activity for friends, a leaderboard based on listening activity, and Blend \\\\u2013 a more prominent/visible version of the current Spotify blend feature. Users also have a more detailed \\"Social\\" profile page and a new Social \\"Awards\\" page that gamifies the listening experience.\'},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\",lineNumber:24,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(\\"img\\",{src:\\"/spotify/spotify-2.png\\",alt:\\"figma screenshots of new social feature for Spotify\\",style:{borderRadius:\\"1rem\\",margin:\\"2rem 0\\"}},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\",lineNumber:25,columnNumber:1},this)]},void 0,!0,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\",lineNumber:1,columnNumber:1},this)}function Er(u={}){let{wrapper:a}=u.components||{};return a?(0,d.jsxDEV)(a,Object.assign({},u,{children:(0,d.jsxDEV)(Ce,u,void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\"},this)}),void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-4f2098b7-ad19-4195-98cc-26900f0c2331.mdx\\"},this):Ce(u)}var Rr=Er;return yr(wr);})();\\n/*! Bundled license information:\\n\\nreact/cjs/react-jsx-dev-runtime.development.js:\\n  (**\\n   * @license React\\n   * react-jsx-dev-runtime.development.js\\n   *\\n   * Copyright (c) Facebook, Inc. and its affiliates.\\n   *\\n   * This source code is licensed under the MIT license found in the\\n   * LICENSE file in the root directory of this source tree.\\n   *)\\n*/\\n;return Component;"},"_id":"projects/spotify.mdx","_raw":{"sourceFilePath":"projects/spotify.mdx","sourceFileName":"spotify.mdx","sourceFileDir":"projects","contentType":"mdx","flattenedPath":"projects/spotify"},"type":"Project","path":"projects/spotify","slug":"spotify"},{"published":true,"title":"Stanford Daily Website Redesign","description":"Stanford Daily main site and blog redesigns","date":"2021-10-01T00:00:00.000Z","url":"https://stanforddaily.com","displayDate":"Fall 2021","category":"Web","body":{"raw":"# Summary\\nDuring the 2021-2022 school year, I helped launch a major redesign of the Stanford Daily’s website, providing content to readers in a more engaging and accessible manner. Through this project, I gained experience in not only specific tools such as Figma and WordPress, but I have also improved my awareness and empathy for delivering to a diverse user and readership base.\\nMy specific tasks included header, footer, and meta box redesign.\\n\\n<img src=\\"/daily/daily-1.png\\" alt=\\"screenshot of Stanford Daily home page\\" style={{  margin: \'2rem 0\' }} />\\n<img src=\\"/daily/daily-2.png\\" alt=\\"screenshot of Stanford Daily footer\\" style={{  margin: \'2rem 0\' }} />\\n\\n# Stanford Dish blog site concepts\\nI also worked on some designs for a then-planned Daily blog site. \\n\\n<img src=\\"/daily/daily-3.png\\" alt=\\"screenshot of blog header concept 1\\" style={{ margin: \'2rem 0\' }} />\\n<img src=\\"/daily/daily-4.png\\" alt=\\"screenshot of blog header concept 2\\" style={{ margin: \'2rem 0\' }} />\\n<img src=\\"/daily/daily-5.png\\" alt=\\"screenshot of blog footer concept 1\\" style={{ margin: \'2rem 0\' }} />\\n<img src=\\"/daily/daily-6.png\\" alt=\\"screenshot of blog footer concept 2\\" style={{ margin: \'2rem 0\' }} />\\n","code":"var Component=(()=>{var dr=Object.create;var A=Object.defineProperty;var pr=Object.getOwnPropertyDescriptor;var mr=Object.getOwnPropertyNames;var vr=Object.getPrototypeOf,br=Object.prototype.hasOwnProperty;var q=(l,i)=>()=>(i||l((i={exports:{}}).exports,i),i.exports),hr=(l,i)=>{for(var h in i)A(l,h,{get:i[h],enumerable:!0})},we=(l,i,h,_)=>{if(i&&typeof i==\\"object\\"||typeof i==\\"function\\")for(let y of mr(i))!br.call(l,y)&&y!==h&&A(l,y,{get:()=>i[y],enumerable:!(_=pr(i,y))||_.enumerable});return l};var gr=(l,i,h)=>(h=l!=null?dr(vr(l)):{},we(i||!l||!l.__esModule?A(h,\\"default\\",{value:l,enumerable:!0}):h,l)),yr=l=>we(A({},\\"__esModule\\",{value:!0}),l);var je=q((jr,xe)=>{xe.exports=React});var Te=q(z=>{\\"use strict\\";(function(){\\"use strict\\";var l=je(),i=Symbol.for(\\"react.element\\"),h=Symbol.for(\\"react.portal\\"),_=Symbol.for(\\"react.fragment\\"),y=Symbol.for(\\"react.strict_mode\\"),H=Symbol.for(\\"react.profiler\\"),J=Symbol.for(\\"react.provider\\"),Z=Symbol.for(\\"react.context\\"),S=Symbol.for(\\"react.forward_ref\\"),U=Symbol.for(\\"react.suspense\\"),I=Symbol.for(\\"react.suspense_list\\"),C=Symbol.for(\\"react.memo\\"),W=Symbol.for(\\"react.lazy\\"),Ce=Symbol.for(\\"react.offscreen\\"),Q=Symbol.iterator,Oe=\\"@@iterator\\";function Pe(e){if(e===null||typeof e!=\\"object\\")return null;var r=Q&&e[Q]||e[Oe];return typeof r==\\"function\\"?r:null}var w=l.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;function p(e){{for(var r=arguments.length,n=new Array(r>1?r-1:0),t=1;t<r;t++)n[t-1]=arguments[t];Ne(\\"error\\",e,n)}}function Ne(e,r,n){{var t=w.ReactDebugCurrentFrame,s=t.getStackAddendum();s!==\\"\\"&&(r+=\\"%s\\",n=n.concat([s]));var c=n.map(function(o){return String(o)});c.unshift(\\"Warning: \\"+r),Function.prototype.apply.call(console[e],console,c)}}var Fe=!1,Ae=!1,Ue=!1,Ie=!1,We=!1,ee;ee=Symbol.for(\\"react.module.reference\\");function Ye(e){return!!(typeof e==\\"string\\"||typeof e==\\"function\\"||e===_||e===H||We||e===y||e===U||e===I||Ie||e===Ce||Fe||Ae||Ue||typeof e==\\"object\\"&&e!==null&&(e.$$typeof===W||e.$$typeof===C||e.$$typeof===J||e.$$typeof===Z||e.$$typeof===S||e.$$typeof===ee||e.getModuleId!==void 0))}function $e(e,r,n){var t=e.displayName;if(t)return t;var s=r.displayName||r.name||\\"\\";return s!==\\"\\"?n+\\"(\\"+s+\\")\\":n}function re(e){return e.displayName||\\"Context\\"}function g(e){if(e==null)return null;if(typeof e.tag==\\"number\\"&&p(\\"Received an unexpected object in getComponentNameFromType(). This is likely a bug in React. Please file an issue.\\"),typeof e==\\"function\\")return e.displayName||e.name||null;if(typeof e==\\"string\\")return e;switch(e){case _:return\\"Fragment\\";case h:return\\"Portal\\";case H:return\\"Profiler\\";case y:return\\"StrictMode\\";case U:return\\"Suspense\\";case I:return\\"SuspenseList\\"}if(typeof e==\\"object\\")switch(e.$$typeof){case Z:var r=e;return re(r)+\\".Consumer\\";case J:var n=e;return re(n._context)+\\".Provider\\";case S:return $e(e,e.render,\\"ForwardRef\\");case C:var t=e.displayName||null;return t!==null?t:g(e.type)||\\"Memo\\";case W:{var s=e,c=s._payload,o=s._init;try{return g(o(c))}catch{return null}}}return null}var E=Object.assign,T=0,ne,te,ae,oe,ie,se,ce;function le(){}le.__reactDisabledLog=!0;function Me(){{if(T===0){ne=console.log,te=console.info,ae=console.warn,oe=console.error,ie=console.group,se=console.groupCollapsed,ce=console.groupEnd;var e={configurable:!0,enumerable:!0,value:le,writable:!0};Object.defineProperties(console,{info:e,log:e,warn:e,error:e,group:e,groupCollapsed:e,groupEnd:e})}T++}}function Ve(){{if(T--,T===0){var e={configurable:!0,enumerable:!0,writable:!0};Object.defineProperties(console,{log:E({},e,{value:ne}),info:E({},e,{value:te}),warn:E({},e,{value:ae}),error:E({},e,{value:oe}),group:E({},e,{value:ie}),groupCollapsed:E({},e,{value:se}),groupEnd:E({},e,{value:ce})})}T<0&&p(\\"disabledDepth fell below zero. This is a bug in React. Please file an issue.\\")}}var Y=w.ReactCurrentDispatcher,$;function O(e,r,n){{if($===void 0)try{throw Error()}catch(s){var t=s.stack.trim().match(/\\\\n( *(at )?)/);$=t&&t[1]||\\"\\"}return`\\n`+$+e}}var M=!1,P;{var Le=typeof WeakMap==\\"function\\"?WeakMap:Map;P=new Le}function ue(e,r){if(!e||M)return\\"\\";{var n=P.get(e);if(n!==void 0)return n}var t;M=!0;var s=Error.prepareStackTrace;Error.prepareStackTrace=void 0;var c;c=Y.current,Y.current=null,Me();try{if(r){var o=function(){throw Error()};if(Object.defineProperty(o.prototype,\\"props\\",{set:function(){throw Error()}}),typeof Reflect==\\"object\\"&&Reflect.construct){try{Reflect.construct(o,[])}catch(v){t=v}Reflect.construct(e,[],o)}else{try{o.call()}catch(v){t=v}e.call(o.prototype)}}else{try{throw Error()}catch(v){t=v}e()}}catch(v){if(v&&t&&typeof v.stack==\\"string\\"){for(var a=v.stack.split(`\\n`),m=t.stack.split(`\\n`),u=a.length-1,f=m.length-1;u>=1&&f>=0&&a[u]!==m[f];)f--;for(;u>=1&&f>=0;u--,f--)if(a[u]!==m[f]){if(u!==1||f!==1)do if(u--,f--,f<0||a[u]!==m[f]){var b=`\\n`+a[u].replace(\\" at new \\",\\" at \\");return e.displayName&&b.includes(\\"<anonymous>\\")&&(b=b.replace(\\"<anonymous>\\",e.displayName)),typeof e==\\"function\\"&&P.set(e,b),b}while(u>=1&&f>=0);break}}}finally{M=!1,Y.current=c,Ve(),Error.prepareStackTrace=s}var j=e?e.displayName||e.name:\\"\\",R=j?O(j):\\"\\";return typeof e==\\"function\\"&&P.set(e,R),R}function Be(e,r,n){return ue(e,!1)}function Ke(e){var r=e.prototype;return!!(r&&r.isReactComponent)}function N(e,r,n){if(e==null)return\\"\\";if(typeof e==\\"function\\")return ue(e,Ke(e));if(typeof e==\\"string\\")return O(e);switch(e){case U:return O(\\"Suspense\\");case I:return O(\\"SuspenseList\\")}if(typeof e==\\"object\\")switch(e.$$typeof){case S:return Be(e.render);case C:return N(e.type,r,n);case W:{var t=e,s=t._payload,c=t._init;try{return N(c(s),r,n)}catch{}}}return\\"\\"}var k=Object.prototype.hasOwnProperty,fe={},de=w.ReactDebugCurrentFrame;function F(e){if(e){var r=e._owner,n=N(e.type,e._source,r?r.type:null);de.setExtraStackFrame(n)}else de.setExtraStackFrame(null)}function Xe(e,r,n,t,s){{var c=Function.call.bind(k);for(var o in e)if(c(e,o)){var a=void 0;try{if(typeof e[o]!=\\"function\\"){var m=Error((t||\\"React class\\")+\\": \\"+n+\\" type `\\"+o+\\"` is invalid; it must be a function, usually from the `prop-types` package, but received `\\"+typeof e[o]+\\"`.This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.\\");throw m.name=\\"Invariant Violation\\",m}a=e[o](r,o,t,n,null,\\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\\")}catch(u){a=u}a&&!(a instanceof Error)&&(F(s),p(\\"%s: type specification of %s `%s` is invalid; the type checker function must return `null` or an `Error` but returned a %s. You may have forgotten to pass an argument to the type checker creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and shape all require an argument).\\",t||\\"React class\\",n,o,typeof a),F(null)),a instanceof Error&&!(a.message in fe)&&(fe[a.message]=!0,F(s),p(\\"Failed %s type: %s\\",n,a.message),F(null))}}}var Ge=Array.isArray;function V(e){return Ge(e)}function qe(e){{var r=typeof Symbol==\\"function\\"&&Symbol.toStringTag,n=r&&e[Symbol.toStringTag]||e.constructor.name||\\"Object\\";return n}}function ze(e){try{return pe(e),!1}catch{return!0}}function pe(e){return\\"\\"+e}function me(e){if(ze(e))return p(\\"The provided key is an unsupported type %s. This value must be coerced to a string before before using it here.\\",qe(e)),pe(e)}var D=w.ReactCurrentOwner,He={key:!0,ref:!0,__self:!0,__source:!0},ve,be,L;L={};function Je(e){if(k.call(e,\\"ref\\")){var r=Object.getOwnPropertyDescriptor(e,\\"ref\\").get;if(r&&r.isReactWarning)return!1}return e.ref!==void 0}function Ze(e){if(k.call(e,\\"key\\")){var r=Object.getOwnPropertyDescriptor(e,\\"key\\").get;if(r&&r.isReactWarning)return!1}return e.key!==void 0}function Qe(e,r){if(typeof e.ref==\\"string\\"&&D.current&&r&&D.current.stateNode!==r){var n=g(D.current.type);L[n]||(p(\'Component \\"%s\\" contains the string ref \\"%s\\". Support for string refs will be removed in a future major release. This case cannot be automatically converted to an arrow function. We ask you to manually fix this case by using useRef() or createRef() instead. Learn more about using refs safely here: https://reactjs.org/link/strict-mode-string-ref\',g(D.current.type),e.ref),L[n]=!0)}}function er(e,r){{var n=function(){ve||(ve=!0,p(\\"%s: `key` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\\",r))};n.isReactWarning=!0,Object.defineProperty(e,\\"key\\",{get:n,configurable:!0})}}function rr(e,r){{var n=function(){be||(be=!0,p(\\"%s: `ref` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\\",r))};n.isReactWarning=!0,Object.defineProperty(e,\\"ref\\",{get:n,configurable:!0})}}var nr=function(e,r,n,t,s,c,o){var a={$$typeof:i,type:e,key:r,ref:n,props:o,_owner:c};return a._store={},Object.defineProperty(a._store,\\"validated\\",{configurable:!1,enumerable:!1,writable:!0,value:!1}),Object.defineProperty(a,\\"_self\\",{configurable:!1,enumerable:!1,writable:!1,value:t}),Object.defineProperty(a,\\"_source\\",{configurable:!1,enumerable:!1,writable:!1,value:s}),Object.freeze&&(Object.freeze(a.props),Object.freeze(a)),a};function tr(e,r,n,t,s){{var c,o={},a=null,m=null;n!==void 0&&(me(n),a=\\"\\"+n),Ze(r)&&(me(r.key),a=\\"\\"+r.key),Je(r)&&(m=r.ref,Qe(r,s));for(c in r)k.call(r,c)&&!He.hasOwnProperty(c)&&(o[c]=r[c]);if(e&&e.defaultProps){var u=e.defaultProps;for(c in u)o[c]===void 0&&(o[c]=u[c])}if(a||m){var f=typeof e==\\"function\\"?e.displayName||e.name||\\"Unknown\\":e;a&&er(o,f),m&&rr(o,f)}return nr(e,a,m,s,t,D.current,o)}}var B=w.ReactCurrentOwner,he=w.ReactDebugCurrentFrame;function x(e){if(e){var r=e._owner,n=N(e.type,e._source,r?r.type:null);he.setExtraStackFrame(n)}else he.setExtraStackFrame(null)}var K;K=!1;function X(e){return typeof e==\\"object\\"&&e!==null&&e.$$typeof===i}function ge(){{if(B.current){var e=g(B.current.type);if(e)return`\\n\\nCheck the render method of \\\\``+e+\\"`.\\"}return\\"\\"}}function ar(e){{if(e!==void 0){var r=e.fileName.replace(/^.*[\\\\\\\\\\\\/]/,\\"\\"),n=e.lineNumber;return`\\n\\nCheck your code at `+r+\\":\\"+n+\\".\\"}return\\"\\"}}var ye={};function or(e){{var r=ge();if(!r){var n=typeof e==\\"string\\"?e:e.displayName||e.name;n&&(r=`\\n\\nCheck the top-level render call using <`+n+\\">.\\")}return r}}function _e(e,r){{if(!e._store||e._store.validated||e.key!=null)return;e._store.validated=!0;var n=or(r);if(ye[n])return;ye[n]=!0;var t=\\"\\";e&&e._owner&&e._owner!==B.current&&(t=\\" It was passed a child from \\"+g(e._owner.type)+\\".\\"),x(e),p(\'Each child in a list should have a unique \\"key\\" prop.%s%s See https://reactjs.org/link/warning-keys for more information.\',n,t),x(null)}}function Ee(e,r){{if(typeof e!=\\"object\\")return;if(V(e))for(var n=0;n<e.length;n++){var t=e[n];X(t)&&_e(t,r)}else if(X(e))e._store&&(e._store.validated=!0);else if(e){var s=Pe(e);if(typeof s==\\"function\\"&&s!==e.entries)for(var c=s.call(e),o;!(o=c.next()).done;)X(o.value)&&_e(o.value,r)}}}function ir(e){{var r=e.type;if(r==null||typeof r==\\"string\\")return;var n;if(typeof r==\\"function\\")n=r.propTypes;else if(typeof r==\\"object\\"&&(r.$$typeof===S||r.$$typeof===C))n=r.propTypes;else return;if(n){var t=g(r);Xe(n,e.props,\\"prop\\",t,e)}else if(r.PropTypes!==void 0&&!K){K=!0;var s=g(r);p(\\"Component %s declared `PropTypes` instead of `propTypes`. Did you misspell the property assignment?\\",s||\\"Unknown\\")}typeof r.getDefaultProps==\\"function\\"&&!r.getDefaultProps.isReactClassApproved&&p(\\"getDefaultProps is only used on classic React.createClass definitions. Use a static property named `defaultProps` instead.\\")}}function sr(e){{for(var r=Object.keys(e.props),n=0;n<r.length;n++){var t=r[n];if(t!==\\"children\\"&&t!==\\"key\\"){x(e),p(\\"Invalid prop `%s` supplied to `React.Fragment`. React.Fragment can only have `key` and `children` props.\\",t),x(null);break}}e.ref!==null&&(x(e),p(\\"Invalid attribute `ref` supplied to `React.Fragment`.\\"),x(null))}}var Re={};function cr(e,r,n,t,s,c){{var o=Ye(e);if(!o){var a=\\"\\";(e===void 0||typeof e==\\"object\\"&&e!==null&&Object.keys(e).length===0)&&(a+=\\" You likely forgot to export your component from the file it\'s defined in, or you might have mixed up default and named imports.\\");var m=ar(s);m?a+=m:a+=ge();var u;e===null?u=\\"null\\":V(e)?u=\\"array\\":e!==void 0&&e.$$typeof===i?(u=\\"<\\"+(g(e.type)||\\"Unknown\\")+\\" />\\",a=\\" Did you accidentally export a JSX literal instead of a component?\\"):u=typeof e,p(\\"React.jsx: type is invalid -- expected a string (for built-in components) or a class/function (for composite components) but got: %s.%s\\",u,a)}var f=tr(e,r,n,s,c);if(f==null)return f;if(o){var b=r.children;if(b!==void 0)if(t)if(V(b)){for(var j=0;j<b.length;j++)Ee(b[j],e);Object.freeze&&Object.freeze(b)}else p(\\"React.jsx: Static children should always be an array. You are likely explicitly calling React.jsxs or React.jsxDEV. Use the Babel transform instead.\\");else Ee(b,e)}if(k.call(r,\\"key\\")){var R=g(e),v=Object.keys(r).filter(function(fr){return fr!==\\"key\\"}),G=v.length>0?\\"{key: someKey, \\"+v.join(\\": ..., \\")+\\": ...}\\":\\"{key: someKey}\\";if(!Re[R+G]){var ur=v.length>0?\\"{\\"+v.join(\\": ..., \\")+\\": ...}\\":\\"{}\\";p(`A props object containing a \\"key\\" prop is being spread into JSX:\\n  let props = %s;\\n  <%s {...props} />\\nReact keys must be passed directly to JSX without using spread:\\n  let props = %s;\\n  <%s key={someKey} {...props} />`,G,R,ur,R),Re[R+G]=!0}}return e===_?sr(f):ir(f),f}}var lr=cr;z.Fragment=_,z.jsxDEV=lr})()});var De=q((kr,ke)=>{\\"use strict\\";ke.exports=Te()});var wr={};hr(wr,{default:()=>Rr,frontmatter:()=>_r});var d=gr(De()),_r={title:\\"Stanford Daily Website Redesign\\",description:\\"Stanford Daily main site and blog redesigns\\",url:\\"https://stanforddaily.com\\",date:\\"2021-10-01\\",displayDate:\\"Fall 2021\\",category:\\"Web\\"};function Se(l){let i=Object.assign({h1:\\"h1\\",a:\\"a\\",span:\\"span\\",p:\\"p\\"},l.components);return(0,d.jsxDEV)(d.Fragment,{children:[(0,d.jsxDEV)(i.h1,{id:\\"summary\\",children:[(0,d.jsxDEV)(i.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#summary\\",children:(0,d.jsxDEV)(i.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\"},this),\\"Summary\\"]},void 0,!0,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\",lineNumber:10,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(i.p,{children:`During the 2021-2022 school year, I helped launch a major redesign of the Stanford Daily\\\\u2019s website, providing content to readers in a more engaging and accessible manner. Through this project, I gained experience in not only specific tools such as Figma and WordPress, but I have also improved my awareness and empathy for delivering to a diverse user and readership base.\\nMy specific tasks included header, footer, and meta box redesign.`},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\",lineNumber:11,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(\\"img\\",{src:\\"/daily/daily-1.png\\",alt:\\"screenshot of Stanford Daily home page\\",style:{margin:\\"2rem 0\\"}},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\",lineNumber:14,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(\\"img\\",{src:\\"/daily/daily-2.png\\",alt:\\"screenshot of Stanford Daily footer\\",style:{margin:\\"2rem 0\\"}},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\",lineNumber:15,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(i.h1,{id:\\"stanford-dish-blog-site-concepts\\",children:[(0,d.jsxDEV)(i.a,{className:\\"subheading-anchor\\",\\"aria-label\\":\\"Link to section\\",href:\\"#stanford-dish-blog-site-concepts\\",children:(0,d.jsxDEV)(i.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\"},this),\\"Stanford Dish blog site concepts\\"]},void 0,!0,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\",lineNumber:17,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(i.p,{children:\\"I also worked on some designs for a then-planned Daily blog site.\\"},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\",lineNumber:18,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(\\"img\\",{src:\\"/daily/daily-3.png\\",alt:\\"screenshot of blog header concept 1\\",style:{margin:\\"2rem 0\\"}},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\",lineNumber:20,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(\\"img\\",{src:\\"/daily/daily-4.png\\",alt:\\"screenshot of blog header concept 2\\",style:{margin:\\"2rem 0\\"}},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\",lineNumber:21,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(\\"img\\",{src:\\"/daily/daily-5.png\\",alt:\\"screenshot of blog footer concept 1\\",style:{margin:\\"2rem 0\\"}},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\",lineNumber:22,columnNumber:1},this),`\\n`,(0,d.jsxDEV)(\\"img\\",{src:\\"/daily/daily-6.png\\",alt:\\"screenshot of blog footer concept 2\\",style:{margin:\\"2rem 0\\"}},void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\",lineNumber:23,columnNumber:1},this)]},void 0,!0,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\",lineNumber:1,columnNumber:1},this)}function Er(l={}){let{wrapper:i}=l.components||{};return i?(0,d.jsxDEV)(i,Object.assign({},l,{children:(0,d.jsxDEV)(Se,l,void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\"},this)}),void 0,!1,{fileName:\\"/Users/ckunchur/Downloads/portfolio-2/content/projects/_mdx_bundler_entry_point-670ebac5-0378-42ee-924e-f0cc82e9dad9.mdx\\"},this):Se(l)}var Rr=Er;return yr(wr);})();\\n/*! Bundled license information:\\n\\nreact/cjs/react-jsx-dev-runtime.development.js:\\n  (**\\n   * @license React\\n   * react-jsx-dev-runtime.development.js\\n   *\\n   * Copyright (c) Facebook, Inc. and its affiliates.\\n   *\\n   * This source code is licensed under the MIT license found in the\\n   * LICENSE file in the root directory of this source tree.\\n   *)\\n*/\\n;return Component;"},"_id":"projects/stanford-daily.mdx","_raw":{"sourceFilePath":"projects/stanford-daily.mdx","sourceFileName":"stanford-daily.mdx","sourceFileDir":"projects","contentType":"mdx","flattenedPath":"projects/stanford-daily"},"type":"Project","path":"projects/stanford-daily","slug":"stanford-daily"}]');[...a];var s=t(3292),c=t(1881);let l=e=>{let{project:n}=e;return(0,r.jsx)(i.default,{href:"/projects/".concat(n.slug),children:(0,r.jsxs)("article",{className:"p-4 md:p-8",children:[(0,r.jsxs)("div",{className:"flex justify-between gap-4 pb-4 items-center",children:[(0,r.jsx)("span",{className:"text-xs duration-1000 text-zinc-200 group-hover:text-white group-hover:border-zinc-200 drop-shadow-orange",children:(0,r.jsx)("span",{children:n.displayDate||"SOON"})}),(0,r.jsx)("span",{className:"px-2 py-1 text-xs font-medium rounded-full bg-zinc-700 text-zinc-200 group-hover:bg-white group-hover:text-zinc-800 transition",children:n.category})]}),(0,r.jsx)("h2",{className:"z-20 text-xl font-medium duration-1000 lg:text-3xl text-zinc-200 group-hover:text-white font-display",children:n.title}),(0,r.jsx)("p",{className:"z-20 mt-4 text-sm duration-1000 text-zinc-400 group-hover:text-zinc-200",children:n.description})]})})};function d(){let[e,n]=(0,o.useState)("all"),t=a.find(e=>"ecovision"===e.slug),d=a.find(e=>"mindstorm"===e.slug),p=a.find(e=>"edusketch"===e.slug),u=a.filter(e=>e.published).filter(n=>"all"===e?n.slug!==t.slug&&n.slug!==d.slug&&n.slug!==p.slug:n.category===e).sort((e,n)=>{var t,r;return new Date(null!==(t=n.date)&&void 0!==t?t:Number.POSITIVE_INFINITY).getTime()-new Date(null!==(r=e.date)&&void 0!==r?r:Number.POSITIVE_INFINITY).getTime()});return(0,r.jsxs)("div",{className:"relative pb-16",children:[(0,r.jsx)(s.W,{}),(0,r.jsxs)("div",{className:"px-6 pt-20 mx-auto space-y-8 max-w-7xl lg:px-8 md:space-y-16 md:pt-24 lg:pt-32",children:[(0,r.jsxs)("div",{className:"flex flex-col lg:flex-row justify-between items-start lg:items-center gap-4 lg:gap-8",children:[(0,r.jsxs)("div",{className:"max-w-2xl",children:[(0,r.jsx)("h2",{className:"text-3xl font-bold tracking-tight text-zinc-100 sm:text-4xl",children:"Projects"}),(0,r.jsx)("p",{className:"mt-4 text-zinc-400",children:"A walkthrough of some of my projects, both coding and design. These projects span mobile, web, and XR, covering domains such as healthcare, wellbeing, sustainability, education, and more."})]}),(0,r.jsxs)("select",{className:"bg-zinc-800 text-zinc-100 rounded-md px-3 py-2 border border-zinc-700 focus:outline-none focus:ring-2 focus:ring-zinc-600 w-full lg:w-auto",value:e,onChange:e=>n(e.target.value),children:[(0,r.jsx)("option",{value:"all",children:"All Categories"}),(0,r.jsx)("option",{value:"Mobile",children:"Mobile"}),(0,r.jsx)("option",{value:"Web",children:"Web"}),(0,r.jsx)("option",{value:"XR",children:"XR"})]})]}),(0,r.jsx)("div",{className:"w-full h-px bg-zinc-800"}),"all"===e?(0,r.jsxs)(r.Fragment,{children:[(0,r.jsxs)("div",{className:"grid grid-cols-1 gap-8 mx-auto lg:grid-cols-2 ",children:[(0,r.jsx)(c.Card,{children:(0,r.jsx)(i.default,{href:"/projects/".concat(t.slug),children:(0,r.jsxs)("article",{className:"relative w-full h-full p-4 md:p-8",children:[(0,r.jsxs)("div",{className:"flex justify-between gap-4 pb-4 items-center",children:[(0,r.jsx)("span",{className:"text-xs duration-1000 text-zinc-200 group-hover:text-white group-hover:border-zinc-200 drop-shadow-orange",children:(0,r.jsx)("span",{children:t.displayDate||"SOON"})}),(0,r.jsx)("span",{className:"px-2 py-1 text-xs font-medium rounded-full bg-zinc-700 text-zinc-200 group-hover:bg-white group-hover:text-zinc-800 transition",children:t.category})]}),(0,r.jsx)("h2",{id:"featured-post",className:"mt-4 text-3xl font-bold text-zinc-100 group-hover:text-white sm:text-4xl font-display",children:t.title}),(0,r.jsx)("p",{className:"mt-4 leading-8 duration-150 text-zinc-400 group-hover:text-zinc-300",children:t.description}),(0,r.jsx)("div",{className:"absolute bottom-4 md:bottom-8",children:(0,r.jsxs)("p",{className:"hidden text-zinc-200 hover:text-zinc-50 lg:block",children:["Read more ",(0,r.jsx)("span",{"aria-hidden":"true",children:"→"})]})})]})})}),(0,r.jsx)("div",{className:"flex flex-col w-full gap-8 mx-auto border-t border-gray-900/10 lg:mx-0 lg:border-t-0 ",children:[d,p].map(e=>(0,r.jsx)(c.Card,{children:(0,r.jsx)(l,{project:e})},e.slug))})]}),(0,r.jsx)("div",{className:"hidden w-full h-px md:block bg-zinc-800"})]}):null,(0,r.jsxs)("div",{className:"grid grid-cols-1 gap-4 mx-auto lg:mx-0 md:grid-cols-3",children:[(0,r.jsx)("div",{className:"grid grid-cols-1 gap-4",children:u.filter((e,n)=>n%3==0).map(e=>(0,r.jsx)(c.Card,{children:(0,r.jsx)(l,{project:e})},e.slug))}),(0,r.jsx)("div",{className:"grid grid-cols-1 gap-4",children:u.filter((e,n)=>n%3==1).map(e=>(0,r.jsx)(c.Card,{children:(0,r.jsx)(l,{project:e})},e.slug))}),(0,r.jsx)("div",{className:"grid grid-cols-1 gap-4",children:u.filter((e,n)=>n%3==2).map(e=>(0,r.jsx)(c.Card,{children:(0,r.jsx)(l,{project:e})},e.slug))})]})]})]})}},8090:function(e,n,t){"use strict";t.d(n,{Z:function(){return a}});var r=t(3387),i={xmlns:"http://www.w3.org/2000/svg",width:24,height:24,viewBox:"0 0 24 24",fill:"none",stroke:"currentColor",strokeWidth:2,strokeLinecap:"round",strokeLinejoin:"round"};let o=e=>e.replace(/([a-z0-9])([A-Z])/g,"$1-$2").toLowerCase(),a=(e,n)=>{let t=(0,r.forwardRef)((t,a)=>{let{color:s="currentColor",size:c=24,strokeWidth:l=2,absoluteStrokeWidth:d,children:p,...u}=t;return(0,r.createElement)("svg",{ref:a,...i,width:c,height:c,stroke:s,strokeWidth:d?24*Number(l)/Number(c):l,className:"lucide lucide-".concat(o(e)),...u},[...n.map(e=>{let[n,t]=e;return(0,r.createElement)(n,t)}),...(Array.isArray(p)?p:[p])||[]])});return t.displayName="".concat(e),t}},3001:function(e,n,t){"use strict";t.d(n,{Z:function(){return r}});let r=(0,t(8090).Z)("ArrowLeft",[["path",{d:"m12 19-7-7 7-7",key:"1l729n"}],["path",{d:"M19 12H5",key:"x3x0zl"}]])},2456:function(e,n,t){"use strict";t.d(n,{default:function(){return i.a}});var r=t(9855),i=t.n(r)}},function(e){e.O(0,[855,664,280,696,744],function(){return e(e.s=7242)}),_N_E=e.O()}]);